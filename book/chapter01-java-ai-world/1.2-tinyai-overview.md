# 1.2 TinyAIé¡¹ç›®æ€»è§ˆï¼šä»é›¶æ„å»ºAIæ¡†æ¶

## å¼•è¨€ï¼šä¸ºä»€ä¹ˆè¦ä»é›¶å¼€å§‹ï¼Ÿ

åœ¨å‰ä¸€èŠ‚ä¸­ï¼Œæˆ‘ä»¬åˆ†æäº†Javaåœ¨AIé¢†åŸŸçš„ç‹¬ç‰¹ä¼˜åŠ¿å’Œç°æœ‰æ¡†æ¶çš„å±€é™æ€§ã€‚ç°åœ¨ä½ å¯èƒ½ä¼šé—®ï¼š**æ—¢ç„¶å·²ç»æœ‰äº†DL4Jã€TensorFlow Javaç­‰æ¡†æ¶ï¼Œä¸ºä»€ä¹ˆè¿˜è¦ä»é›¶å¼€å§‹æ„å»ºä¸€ä¸ªæ–°çš„AIæ¡†æ¶ï¼Ÿ**

ç­”æ¡ˆå¾ˆç®€å•ï¼š**å­¦ä¹ å’Œç†è§£çš„æœ€ä½³æ–¹å¼å°±æ˜¯äº²æ‰‹æ„å»º**ã€‚

æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœä½ æƒ³æˆä¸ºä¸€ä½ä¼˜ç§€çš„å»ºç­‘å¸ˆï¼Œä½ ä¼šé€‰æ‹©ï¼š
- A) åªå­¦ä¼šä½¿ç”¨ç°æˆçš„å»ºç­‘å·¥å…·å’Œææ–™
- B) äº†è§£æ¯ä¸€å—ç –ã€æ¯ä¸€æ ¹æ¢çš„ä½œç”¨åŸç†

æ˜¾ç„¶ï¼ŒBé€‰é¡¹ä¼šè®©ä½ å¯¹å»ºç­‘æœ‰æ›´æ·±å…¥çš„ç†è§£ã€‚åŒæ ·çš„é“ç†ï¼Œé€šè¿‡ä»é›¶æ„å»ºAIæ¡†æ¶ï¼Œæˆ‘ä»¬èƒ½å¤Ÿï¼š

1. **æ·±å…¥ç†è§£AIç®—æ³•çš„æœ¬è´¨**ï¼šä¸å†æ˜¯é»‘ç›’è°ƒç”¨ï¼Œè€Œæ˜¯çŸ¥å…¶ç„¶çŸ¥å…¶æ‰€ä»¥ç„¶
2. **æŒæ¡ç³»ç»Ÿè®¾è®¡èƒ½åŠ›**ï¼šå­¦ä¼šå¦‚ä½•è®¾è®¡å¯æ‰©å±•ã€é«˜æ€§èƒ½çš„AIç³»ç»Ÿ
3. **å»ºç«‹å·¥ç¨‹æ€ç»´**ï¼šåœ¨è¿½æ±‚ç®—æ³•ç²¾åº¦çš„åŒæ—¶ï¼Œå…¼é¡¾å·¥ç¨‹å®è·µçš„å„ç§çº¦æŸ

## TinyAIé¡¹ç›®æ„¿æ™¯ä¸ç›®æ ‡

### é¡¹ç›®æ„¿æ™¯
**æ„å»ºä¸€ä¸ªçº¯Javaå®ç°çš„ã€æ•™å­¦å‹å¥½çš„ã€ç”Ÿäº§å¯ç”¨çš„è½»é‡çº§AIæ¡†æ¶**

```mermaid
graph TB
    subgraph "TinyAIæ ¸å¿ƒä»·å€¼"
        A[æ•™å­¦å‹å¥½<br/>ä»£ç æ¸…æ™°æ˜“æ‡‚]
        B[ç”Ÿäº§å¯ç”¨<br/>æ€§èƒ½å’Œå¯é æ€§å…¼é¡¾]
        C[JavaåŸç”Ÿ<br/>é›¶ç¬¬ä¸‰æ–¹AIåº“ä¾èµ–]
        D[æ¨¡å—åŒ–è®¾è®¡<br/>ç»„ä»¶å¯ç‹¬ç«‹ä½¿ç”¨]
    end
    
    subgraph "ç›®æ ‡ç”¨æˆ·"
        E[Javaç¨‹åºå‘˜<br/>æƒ³è¦è½¬å‹AI]
        F[AIç ”ç©¶è€…<br/>éœ€è¦Javaå®ç°]
        G[ä¼ä¸šå¼€å‘è€…<br/>æ„å»ºAIäº§å“]
        H[æ•™è‚²å·¥ä½œè€…<br/>AIè¯¾ç¨‹æ•™å­¦]
    end
    
    A --> E
    B --> G
    C --> F
    D --> H
```

### æ ¸å¿ƒè®¾è®¡åŸåˆ™

#### 1. ç®€æ´æ€§åŸåˆ™ (Simplicity First)
```java
// TinyAIçš„APIè®¾è®¡ï¼šç®€æ´ç›´è§‚
Variable x = Variable.of(ndarray);
Variable y = x.relu().linear(128).softmax();
Loss loss = CrossEntropyLoss.of(y, target);
loss.backward();
```

ä¸å…¶ä»–æ¡†æ¶ç›¸æ¯”ï¼ŒTinyAIè¿½æ±‚æœ€å°åŒ–çš„APIè¡¨é¢ç§¯ï¼Œè®©å¼€å‘è€…èƒ½å¤Ÿç”¨æœ€å°‘çš„ä»£ç è¡¨è¾¾æœ€å¤æ‚çš„AIæ¦‚å¿µã€‚

#### 2. é€æ˜æ€§åŸåˆ™ (Transparency)
```java
public class LinearLayer extends Layer {
    @Override
    public Variable layerForward(Variable input) {
        // æ¯ä¸€æ­¥éƒ½æ¸…æ™°å¯è§ï¼Œæ²¡æœ‰éšè—çš„é­”æ³•
        Variable result = input.matmul(this.weight);
        if (bias != null) {
            result = result.add(bias);
        }
        return result;
    }
}
```

æ¯ä¸ªæ“ä½œçš„å®ç°éƒ½æ˜¯é€æ˜çš„ï¼Œä½ å¯ä»¥æ·±å…¥åˆ°ä»»ä½•å±‚çº§æŸ¥çœ‹å…·ä½“çš„è®¡ç®—é€»è¾‘ã€‚

#### 3. æ¨¡å—åŒ–åŸåˆ™ (Modularity)
```java
// å„ä¸ªæ¨¡å—å¯ä»¥ç‹¬ç«‹ä½¿ç”¨
NdArray array = new NdArray(data);           // æ•°å€¼è®¡ç®—æ¨¡å—
Variable var = new Variable(array, true);    // è‡ªåŠ¨å¾®åˆ†æ¨¡å—
Model model = new MLP(784, 128, 10);         // ç¥ç»ç½‘ç»œæ¨¡å—
Trainer trainer = new AdamTrainer(model);    // è®­ç»ƒæ¨¡å—
```

æ¯ä¸ªæ¨¡å—éƒ½æœ‰æ¸…æ™°çš„èŒè´£è¾¹ç•Œï¼Œå¯ä»¥å•ç‹¬ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ç»„åˆä½¿ç”¨ã€‚

#### 4. æ€§èƒ½ä¼˜åŒ–åŸåˆ™ (Performance Aware)
```java
public class NdArray {
    // å†…å­˜å¸ƒå±€ä¼˜åŒ–
    private float[] data;              // ä½¿ç”¨åŸç”Ÿæ•°ç»„
    private Shape shape;               // å½¢çŠ¶ä¿¡æ¯åˆ†ç¦»
    private Stride stride;             // æ­¥é•¿ä¿¡æ¯ç”¨äºå¹¿æ’­
    
    // JITç¼–è¯‘å‹å¥½çš„çƒ­ç‚¹æ–¹æ³•
    public void addInplace(NdArray other) {
        // é¿å…å¯¹è±¡åˆ›å»ºï¼Œç›´æ¥ä¿®æ”¹ç°æœ‰æ•°æ®
        for (int i = 0; i < data.length; i++) {
            data[i] += other.data[i];
        }
    }
}
```

## TinyAIæŠ€æœ¯æ¶æ„è¯¦è§£

### æ•´ä½“æ¶æ„è®¾è®¡

```mermaid
graph TB
    subgraph "ğŸ¯ åº”ç”¨å±‚"
        App1[æ™ºèƒ½å®¢æœ]
        App2[ä»£ç ç”Ÿæˆ]
        App3[è‡ªåŠ¨é©¾é©¶]
        App4[å›¾åƒç”Ÿæˆ]
    end
    
    subgraph "ğŸ¤– æ™ºèƒ½ä½“å±‚ (7ä¸ªæ¨¡å—)"
        Agent1[context - åŸºç¡€æ¡†æ¶]
        Agent2[rag - æ£€ç´¢å¢å¼º]
        Agent3[multi - å¤šæ™ºèƒ½ä½“]
        Agent4[evol - è‡ªè¿›åŒ–]
        Agent5[pattern - è®¤çŸ¥æ¨¡å¼]
        Agent6[research - æ·±åº¦ç ”ç©¶]
        Agent7[manus - æ‰‹ç¨¿æ™ºèƒ½ä½“]
    end
    
    subgraph "ğŸ§  æ¨¡å‹å±‚ (6ä¸ªæ¨¡å—)"
        Model1[gpt - GPTç³»åˆ—]
        Model2[deepseek - R1/V3]
        Model3[qwen - Qwen3]
        Model4[minimind - è½»é‡çº§LLM]
        Model5[banana - å¤šæ¨¡æ€]
        Model6[lora - å‚æ•°é«˜æ•ˆå¾®è°ƒ]
    end
    
    subgraph "ğŸ‹ï¸ å…·èº«æ™ºèƒ½å±‚ (4ä¸ªæ¨¡å—)"
        Embodied1[base - è‡ªåŠ¨é©¾é©¶]
        Embodied2[robot - æ‰«åœ°æœºå™¨äºº]
        Embodied3[vla - VLAæ¶æ„]
        Embodied4[wm - ä¸–ç•Œæ¨¡å‹]
    end
    
    subgraph "ğŸš€ æ¡†æ¶å±‚ (4ä¸ªæ¨¡å—)"
        Framework1[ml - æœºå™¨å­¦ä¹ æ ¸å¿ƒ]
        Framework2[nnet - ç¥ç»ç½‘ç»œå±‚]
        Framework3[rl - å¼ºåŒ–å­¦ä¹ ]
        Framework4[nl - è‡ªç„¶è¯­è¨€å¤„ç†]
    end
    
    subgraph "âš¡ å¼•æ“å±‚ (1ä¸ªæ¨¡å—)"
        Engine1[func - è‡ªåŠ¨å¾®åˆ†å¼•æ“]
    end
    
    subgraph "ğŸ§® åŸºç¡€å±‚ (1ä¸ªæ¨¡å—)"
        Base1[ndarr - å¤šç»´æ•°ç»„åº“]
    end
    
    App1 --> Agent1
    App2 --> Model1
    App3 --> Embodied1
    App4 --> Model5
    
    Agent1 --> Framework1
    Model1 --> Framework1
    Embodied1 --> Framework3
    
    Framework1 --> Engine1
    Framework3 --> Engine1
    
    Engine1 --> Base1
```

### æ ¸å¿ƒæ¨¡å—è¯¦è§£

#### 1. æ•°å€¼åŸºç¡€å±‚ (tinyai-deeplearning-ndarr)
è¿™æ˜¯æ•´ä¸ªæ¡†æ¶çš„åŸºçŸ³ï¼Œæä¾›é«˜æ€§èƒ½çš„å¤šç»´æ•°ç»„æ“ä½œï¼š

```java
// å¤šç»´æ•°ç»„çš„åˆ›å»ºå’Œæ“ä½œ
NdArray matrix = NdArray.create(new float[][]{
    {1.0f, 2.0f, 3.0f},
    {4.0f, 5.0f, 6.0f}
});

// æ”¯æŒå¤æ‚çš„æ•°å­¦è¿ç®—
NdArray result = matrix.multiply(2.0f)      // æ ‡é‡ä¹˜æ³•
                      .add(bias)            // çŸ©é˜µåŠ æ³•
                      .transpose()          // çŸ©é˜µè½¬ç½®
                      .reshape(3, 2);       // å½¢çŠ¶å˜æ¢
```

**è®¾è®¡ç‰¹è‰²**ï¼š
- **é›¶æ‹·è´æ“ä½œ**ï¼šå°½å¯èƒ½é¿å…æ•°æ®å¤åˆ¶
- **å¹¿æ’­æœºåˆ¶**ï¼šè‡ªåŠ¨å¤„ç†ä¸åŒå½¢çŠ¶çš„æ•°ç»„è¿ç®—
- **å†…å­˜æ± ç®¡ç†**ï¼šå‡å°‘GCå‹åŠ›
- **SIMDä¼˜åŒ–**ï¼šåˆ©ç”¨ç°ä»£CPUçš„å‘é‡åŒ–æŒ‡ä»¤

#### 2. è‡ªåŠ¨å¾®åˆ†å¼•æ“ (tinyai-deeplearning-func)
å®ç°äº†å®Œæ•´çš„è®¡ç®—å›¾å’Œåå‘ä¼ æ’­æœºåˆ¶ï¼š

```java
// æ„å»ºè®¡ç®—å›¾
Variable x = Variable.of(inputData, true);    // requires_grad=true
Variable w = Variable.of(weights, true);
Variable b = Variable.of(bias, true);

// å‰å‘ä¼ æ’­
Variable y = x.matmul(w).add(b).relu();

// åå‘ä¼ æ’­
y.backward();

// è·å–æ¢¯åº¦
NdArray wGrad = w.getGrad();
NdArray bGrad = b.getGrad();
```

**æŠ€æœ¯äº®ç‚¹**ï¼š
- **åŠ¨æ€è®¡ç®—å›¾**ï¼šç±»ä¼¼PyTorchçš„Eageræ¨¡å¼
- **å†…å­˜ä¼˜åŒ–**ï¼šåŠæ—¶é‡Šæ”¾ä¸éœ€è¦çš„ä¸­é—´ç»“æœ
- **æ¢¯åº¦æ£€æŸ¥**ï¼šå†…ç½®æ•°å€¼æ¢¯åº¦éªŒè¯åŠŸèƒ½
- **é«˜é˜¶å¯¼æ•°**ï¼šæ”¯æŒäºŒé˜¶åŠæ›´é«˜é˜¶å¯¼æ•°è®¡ç®—

#### 3. ç¥ç»ç½‘ç»œå±‚ (tinyai-deeplearning-nnet)
æä¾›äº†ä¸°å¯Œçš„ç½‘ç»œå±‚å’Œæ¿€æ´»å‡½æ•°ï¼š

```java
// æ„å»ºæ·±åº¦ç¥ç»ç½‘ç»œ
Sequential model = new Sequential(
    new Linear("fc1", 784, 256),
    new ReLU("relu1"),
    new Dropout("dropout1", 0.5),
    new Linear("fc2", 256, 128),
    new BatchNorm1d("bn1", 128),
    new ReLU("relu2"),
    new Linear("fc3", 128, 10),
    new Softmax("softmax")
);

// å‰å‘ä¼ æ’­
Variable output = model.forward(input);
```

**æ”¯æŒçš„å±‚ç±»å‹**ï¼š
- **å…¨è¿æ¥å±‚**ï¼šLinearã€Dense
- **å·ç§¯å±‚**ï¼šConv1dã€Conv2dã€ConvTranspose2d
- **æ± åŒ–å±‚**ï¼šMaxPoolã€AvgPoolã€AdaptivePool
- **å½’ä¸€åŒ–å±‚**ï¼šBatchNormã€LayerNormã€GroupNorm
- **æ³¨æ„åŠ›æœºåˆ¶**ï¼šMultiHeadAttentionã€SelfAttention

#### 4. è®­ç»ƒå¼•æ“ (tinyai-deeplearning-ml)
æä¾›å®Œæ•´çš„æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–åŠŸèƒ½ï¼š

```java
// é…ç½®è®­ç»ƒå™¨
Trainer trainer = Trainer.builder()
    .model(model)
    .optimizer(new Adam(0.001))
    .lossFunction(new CrossEntropyLoss())
    .device(Device.GPU)
    .build();

// è®­ç»ƒå¾ªç¯
for (int epoch = 0; epoch < 100; epoch++) {
    for (DataBatch batch : dataLoader) {
        TrainingResult result = trainer.trainBatch(batch);
        System.out.printf("Epoch %d, Loss: %.4f, Acc: %.2f%%\n", 
                         epoch, result.getLoss(), result.getAccuracy() * 100);
    }
}
```

**ä¼˜åŒ–å™¨æ”¯æŒ**ï¼š
- **åŸºç¡€ä¼˜åŒ–å™¨**ï¼šSGDã€Momentum
- **è‡ªé€‚åº”ä¼˜åŒ–å™¨**ï¼šAdamã€AdamWã€RMSprop
- **å­¦ä¹ ç‡è°ƒåº¦**ï¼šStepLRã€ExponentialLRã€CosineAnnealingLR
- **æ­£åˆ™åŒ–æŠ€æœ¯**ï¼šWeightDecayã€GradientClipping

## ä»£ç ç»„ç»‡ä¸é¡¹ç›®ç»“æ„

### Mavenæ¨¡å—åŒ–è®¾è®¡
```
TinyAI/
â”œâ”€â”€ tinyai-deeplearning-ndarr/     # å¤šç»´æ•°ç»„åŸºç¡€åº“
â”‚   â”œâ”€â”€ src/main/java/
â”‚   â”‚   â””â”€â”€ org/tinyai/ndarr/
â”‚   â”‚       â”œâ”€â”€ NdArray.java       # æ ¸å¿ƒæ•°ç»„ç±»
â”‚   â”‚       â”œâ”€â”€ Shape.java         # å½¢çŠ¶ç®¡ç†
â”‚   â”‚       â””â”€â”€ ops/              # æ•°å€¼è¿ç®—
â”œâ”€â”€ tinyai-deeplearning-func/     # è‡ªåŠ¨å¾®åˆ†å¼•æ“
â”‚   â”œâ”€â”€ src/main/java/
â”‚   â”‚   â””â”€â”€ org/tinyai/func/
â”‚   â”‚       â”œâ”€â”€ Variable.java      # å˜é‡ç±»
â”‚   â”‚       â”œâ”€â”€ Function.java      # å‡½æ•°æŠ½è±¡
â”‚   â”‚       â””â”€â”€ functions/        # å…·ä½“å‡½æ•°å®ç°
â”œâ”€â”€ tinyai-deeplearning-nnet/     # ç¥ç»ç½‘ç»œå±‚
â”‚   â”œâ”€â”€ src/main/java/
â”‚   â”‚   â””â”€â”€ org/tinyai/nnet/
â”‚   â”‚       â”œâ”€â”€ Layer.java         # å±‚æŠ½è±¡
â”‚   â”‚       â”œâ”€â”€ Block.java         # æ¨¡å—æŠ½è±¡
â”‚   â”‚       â””â”€â”€ layers/           # å…·ä½“å±‚å®ç°
â””â”€â”€ tinyai-deeplearning-ml/       # æœºå™¨å­¦ä¹ æ ¸å¿ƒ
    â”œâ”€â”€ src/main/java/
    â”‚   â””â”€â”€ org/tinyai/ml/
    â”‚       â”œâ”€â”€ Model.java         # æ¨¡å‹æŠ½è±¡
    â”‚       â”œâ”€â”€ Trainer.java       # è®­ç»ƒå™¨
    â”‚       â””â”€â”€ optimizers/       # ä¼˜åŒ–å™¨å®ç°
```

### ä¾èµ–å…³ç³»ç®¡ç†
```mermaid
graph TB
    A[tinyai-deeplearning-ml]
    B[tinyai-deeplearning-nnet]
    C[tinyai-deeplearning-func]
    D[tinyai-deeplearning-ndarr]
    
    A --> B
    A --> C
    B --> C
    C --> D
    
    A -.->|ä½¿ç”¨| E[æ¨¡å‹è®­ç»ƒå’Œä¼˜åŒ–]
    B -.->|æä¾›| F[ç¥ç»ç½‘ç»œå±‚]
    C -.->|æä¾›| G[è‡ªåŠ¨å¾®åˆ†èƒ½åŠ›]
    D -.->|æä¾›| H[æ•°å€¼è®¡ç®—åŸºç¡€]
```

**ä¾èµ–åŸåˆ™**ï¼š
- **å•å‘ä¾èµ–**ï¼šä¸Šå±‚æ¨¡å—ä¾èµ–ä¸‹å±‚æ¨¡å—ï¼Œåä¹‹ä¸æˆç«‹
- **æœ€å°ä¾èµ–**ï¼šæ¯ä¸ªæ¨¡å—åªä¾èµ–å¿…éœ€çš„ç»„ä»¶
- **æ¥å£éš”ç¦»**ï¼šé€šè¿‡æ¥å£å®šä¹‰æ¨¡å—é—´çš„äº¤äº’å¥‘çº¦

## æ€§èƒ½è®¾è®¡è€ƒè™‘

### å†…å­˜ç®¡ç†ç­–ç•¥

#### 1. å¯¹è±¡æ± æ¨¡å¼
```java
public class NdArrayPool {
    private static final ThreadLocal<Queue<NdArray>> POOL = 
        ThreadLocal.withInitial(() -> new ArrayDeque<>());
    
    public static NdArray acquire(Shape shape) {
        Queue<NdArray> pool = POOL.get();
        NdArray array = pool.poll();
        if (array == null || !array.getShape().equals(shape)) {
            array = new NdArray(shape);
        }
        return array;
    }
    
    public static void release(NdArray array) {
        array.zero();  // æ¸…é›¶æ•°æ®
        POOL.get().offer(array);
    }
}
```

#### 2. å†…å­˜æ˜ å°„æ–‡ä»¶
```java
public class LargeDataset {
    private MappedByteBuffer buffer;
    
    public LargeDataset(String filename) throws IOException {
        FileChannel channel = FileChannel.open(
            Paths.get(filename), StandardOpenOption.READ);
        this.buffer = channel.map(
            FileChannel.MapMode.READ_ONLY, 0, channel.size());
    }
    
    public NdArray getBatch(int batchIndex, int batchSize) {
        // ç›´æ¥ä»å†…å­˜æ˜ å°„ä¸­è¯»å–æ•°æ®ï¼Œé¿å…åŠ è½½æ•´ä¸ªæ•°æ®é›†
        int offset = batchIndex * batchSize * Float.BYTES;
        FloatBuffer slice = buffer.asFloatBuffer();
        slice.position(offset);
        
        float[] data = new float[batchSize];
        slice.get(data);
        return NdArray.of(data);
    }
}
```

### å¹¶è¡Œè®¡ç®—ä¼˜åŒ–

#### 1. æ•°æ®å¹¶è¡Œ
```java
public class ParallelComputation {
    private static final ForkJoinPool POOL = new ForkJoinPool();
    
    public static NdArray parallelAdd(NdArray a, NdArray b) {
        if (a.size() < 1000) {
            return a.add(b);  // å°æ•°ç»„ç›´æ¥è®¡ç®—
        }
        
        return POOL.submit(() -> {
            // åˆ†æ²»ç®—æ³•å®ç°å¹¶è¡ŒåŠ æ³•
            return divideAndConquerAdd(a, b, 0, a.size());
        }).join();
    }
}
```

#### 2. æµæ°´çº¿å¹¶è¡Œ
```java
public class PipelineTrainer {
    private final BlockingQueue<DataBatch> dataQueue = new LinkedBlockingQueue<>();
    private final BlockingQueue<TrainingResult> resultQueue = new LinkedBlockingQueue<>();
    
    public void startPipelineTraining() {
        // æ•°æ®åŠ è½½çº¿ç¨‹
        CompletableFuture.runAsync(this::loadData);
        
        // å‰å‘ä¼ æ’­çº¿ç¨‹
        CompletableFuture.runAsync(this::forwardPass);
        
        // åå‘ä¼ æ’­çº¿ç¨‹
        CompletableFuture.runAsync(this::backwardPass);
        
        // å‚æ•°æ›´æ–°çº¿ç¨‹
        CompletableFuture.runAsync(this::updateParameters);
    }
}
```

## ä¸ç”Ÿäº§ç¯å¢ƒçš„å¯¹æ¥

### æ¨¡å‹åºåˆ—åŒ–ä¸éƒ¨ç½²
```java
public class ModelSerializer {
    public void saveModel(Model model, String filename) throws IOException {
        ModelCheckpoint checkpoint = new ModelCheckpoint(
            model.getStateDict(),
            model.getConfiguration(),
            getMetadata()
        );
        
        try (ObjectOutputStream oos = new ObjectOutputStream(
                new FileOutputStream(filename))) {
            oos.writeObject(checkpoint);
        }
    }
    
    public Model loadModel(String filename) throws IOException, ClassNotFoundException {
        try (ObjectInputStream ois = new ObjectInputStream(
                new FileInputStream(filename))) {
            ModelCheckpoint checkpoint = (ModelCheckpoint) ois.readObject();
            return Model.fromCheckpoint(checkpoint);
        }
    }
}
```

### REST APIé›†æˆ
```java
@RestController
@RequestMapping("/api/model")
public class ModelController {
    
    @Autowired
    private ModelService modelService;
    
    @PostMapping("/predict")
    public ResponseEntity<PredictionResult> predict(
            @RequestBody PredictionRequest request) {
        
        try {
            NdArray input = NdArray.of(request.getData());
            Variable output = modelService.predict(input);
            
            return ResponseEntity.ok(new PredictionResult(
                output.toArray(), 
                System.currentTimeMillis()
            ));
        } catch (Exception e) {
            return ResponseEntity.status(HttpStatus.INTERNAL_SERVER_ERROR)
                .body(new PredictionResult("é¢„æµ‹å¤±è´¥: " + e.getMessage()));
        }
    }
}
```

## å°èŠ‚æ€»ç»“

### æ ¸å¿ƒè¦ç‚¹
1. **æ•™è‚²ä»·å€¼**ï¼šTinyAIé€šè¿‡ä»é›¶æ„å»ºçš„æ–¹å¼ï¼Œå¸®åŠ©å¼€å‘è€…æ·±å…¥ç†è§£AIæŠ€æœ¯çš„æœ¬è´¨
2. **æ¶æ„è®¾è®¡**ï¼šé‡‡ç”¨åˆ†å±‚æ¨¡å—åŒ–è®¾è®¡ï¼Œæ¯ä¸€å±‚éƒ½æœ‰æ¸…æ™°çš„èŒè´£å’Œæ¥å£
3. **æ€§èƒ½ä¼˜åŒ–**ï¼šåœ¨ä¿æŒä»£ç å¯è¯»æ€§çš„åŒæ—¶ï¼Œé€šè¿‡å¤šç§æŠ€æœ¯æ‰‹æ®µå®ç°é«˜æ€§èƒ½
4. **ç”Ÿäº§å°±ç»ª**ï¼šæä¾›å®Œæ•´çš„æ¨¡å‹è®­ç»ƒã€åºåˆ—åŒ–ã€éƒ¨ç½²èƒ½åŠ›

### è®¾è®¡ç†å¿µ
- **ç®€æ´æ€§**ï¼šæœ€å°åŒ–APIè¡¨é¢ç§¯ï¼Œé™ä½å­¦ä¹ æˆæœ¬
- **é€æ˜æ€§**ï¼šæ¯ä¸ªæ“ä½œéƒ½æ˜¯å¯è§å’Œå¯ç†è§£çš„
- **æ¨¡å—åŒ–**ï¼šç»„ä»¶å¯ç‹¬ç«‹ä½¿ç”¨ï¼Œä¹Ÿå¯ç»„åˆä½¿ç”¨
- **æ€§èƒ½**ï¼šåœ¨æ•™å­¦å‹å¥½çš„å‰æä¸‹ï¼Œè¿½æ±‚ç”Ÿäº§çº§æ€§èƒ½

### é¡¹ç›®ä»·å€¼
TinyAIä¸ä»…ä»…æ˜¯ä¸€ä¸ªAIæ¡†æ¶ï¼Œæ›´æ˜¯ä¸€ä¸ª**å­¦ä¹ AIæŠ€æœ¯çš„æœ€ä½³å®è·µå¹³å°**ã€‚é€šè¿‡è¿™ä¸ªé¡¹ç›®ï¼ŒJavaç¨‹åºå‘˜å¯ä»¥ï¼š
- æŒæ¡AIç®—æ³•çš„æ ¸å¿ƒåŸç†
- å­¦ä¼šé«˜æ€§èƒ½ç³»ç»Ÿçš„è®¾è®¡æ–¹æ³•
- å»ºç«‹å®Œæ•´çš„AIå·¥ç¨‹åŒ–æ€ç»´
- åœ¨AIæ—¶ä»£æ‰¾åˆ°è‡ªå·±çš„æŠ€æœ¯å®šä½

## æ€è€ƒé¢˜

1. **æ¶æ„è®¾è®¡é¢˜**ï¼šå¦‚æœè¦åœ¨TinyAIä¸­æ·»åŠ GPUåŠ é€Ÿæ”¯æŒï¼Œä½ ä¼šå¦‚ä½•è®¾è®¡æ¶æ„ï¼Ÿéœ€è¦ä¿®æ”¹å“ªäº›æ¨¡å—ï¼Ÿ

2. **æ€§èƒ½ä¼˜åŒ–é¢˜**ï¼šå¯¹äºå¤§è§„æ¨¡çŸ©é˜µä¹˜æ³•è¿ç®—ï¼Œé™¤äº†æ–‡ä¸­æåˆ°çš„æ–¹æ³•ï¼Œä½ è¿˜èƒ½æƒ³åˆ°å“ªäº›ä¼˜åŒ–ç­–ç•¥ï¼Ÿ

3. **æ‰©å±•æ€§æ€è€ƒ**ï¼šå¦‚æœè¦æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒï¼ŒTinyAIçš„æ¶æ„éœ€è¦åšå“ªäº›è°ƒæ•´ï¼Ÿ

4. **å¯¹æ¯”åˆ†æé¢˜**ï¼šç›¸æ¯”äºPyTorchæˆ–TensorFlowï¼ŒTinyAIçš„è®¾è®¡æœ‰å“ªäº›ç‹¬ç‰¹ä¼˜åŠ¿å’Œå±€é™æ€§ï¼Ÿ

## æ‹“å±•é˜…è¯»

- **Javaæ€§èƒ½ä¼˜åŒ–**ï¼šã€ŠJavaæ€§èƒ½æƒå¨æŒ‡å—ã€‹
- **å¹¶å‘ç¼–ç¨‹**ï¼šã€ŠJavaå¹¶å‘ç¼–ç¨‹å®æˆ˜ã€‹
- **æ·±åº¦å­¦ä¹ æ¡†æ¶è®¾è®¡**ï¼šPyTorchæºç åˆ†æ
- **ä¼ä¸šçº§æ¶æ„**ï¼šã€Šè½¯ä»¶æ¶æ„å®è·µã€‹

---

**æœ¬å°èŠ‚å®Œ**ï¼šä¸‹ä¸€å°èŠ‚æˆ‘ä»¬å°†è¿›å…¥å®æˆ˜ç¯èŠ‚ï¼Œæ­å»ºå¼€å‘ç¯å¢ƒå¹¶è¿è¡Œç¬¬ä¸€ä¸ªAIç¨‹åºã€‚