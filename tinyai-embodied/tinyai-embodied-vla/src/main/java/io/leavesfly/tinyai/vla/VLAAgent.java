package io.leavesfly.tinyai.vla;

import io.leavesfly.tinyai.vla.decoder.ActionDecoder;
import io.leavesfly.tinyai.vla.decoder.LanguageFeedbackGenerator;
import io.leavesfly.tinyai.vla.encoder.LanguageEncoder;
import io.leavesfly.tinyai.vla.encoder.ProprioceptionEncoder;
import io.leavesfly.tinyai.vla.encoder.VisionEncoder;
import io.leavesfly.tinyai.vla.fusion.CrossModalAttention;
import io.leavesfly.tinyai.vla.fusion.VLATransformerCore;

import io.leavesfly.tinyai.ndarr.NdArray;
import io.leavesfly.tinyai.func.Variable;
import io.leavesfly.tinyai.vla.model.VLAAction;
import io.leavesfly.tinyai.vla.model.VLAState;

/**
 * VLA智能体核心
 * 集成视觉、语言、动作三种模态的端到端具身智能系统
 * 
 * @author TinyAI
 */
public class VLAAgent {
    
    // 配置参数
    private final int hiddenDim;
    private final int numHeads;
    private final int numLayers;
    private final int actionDim;
    
    // 编码器
    private final VisionEncoder visionEncoder;
    private final LanguageEncoder languageEncoder;
    private final ProprioceptionEncoder proprioceptionEncoder;
    
    // 融合层
    private final CrossModalAttention crossModalAttention;
    private final VLATransformerCore transformerCore;
    
    // 解码器
    private final ActionDecoder actionDecoder;
    private final LanguageFeedbackGenerator feedbackGenerator;
    
    /**
     * 构造函数
     * 
     * @param hiddenDim 隐藏层维度
     * @param numHeads 注意力头数
     * @param numLayers Transformer层数
     * @param actionDim 动作维度
     */
    public VLAAgent(int hiddenDim, int numHeads, int numLayers, int actionDim) {
        this.hiddenDim = hiddenDim;
        this.numHeads = numHeads;
        this.numLayers = numLayers;
        this.actionDim = actionDim;
        
        // 初始化编码器
        this.visionEncoder = new VisionEncoder(3, hiddenDim, 64, 8);
        this.languageEncoder = new LanguageEncoder(10000, hiddenDim, 128, 6);
        this.proprioceptionEncoder = new ProprioceptionEncoder(15, hiddenDim);
        
        // 初始化融合层
        this.crossModalAttention = new CrossModalAttention(hiddenDim, numHeads);
        this.transformerCore = new VLATransformerCore(hiddenDim, numLayers, numHeads);
        
        // 初始化解码器
        this.actionDecoder = new ActionDecoder(hiddenDim, actionDim, 7);
        this.feedbackGenerator = new LanguageFeedbackGenerator();
        
        System.out.println("VLAAgent initialized with:");
        System.out.println("  Hidden Dim: " + hiddenDim);
        System.out.println("  Num Heads: " + numHeads);
        System.out.println("  Num Layers: " + numLayers);
        System.out.println("  Action Dim: " + actionDim);
    }
    
    /**
     * 预测动作
     * 
     * @param state VLA状态
     * @return VLA动作
     */
    public VLAAction predict(VLAState state) {
        // 1. 编码各模态输入
        NdArray visionFeatures = visionEncoder.encode(state.getVisionInput());
        NdArray languageFeatures = languageEncoder.encode(state.getLanguageInput());
        
        NdArray proprioFeatures = null;
        if (state.getProprioceptionInput() != null) {
            proprioFeatures = proprioceptionEncoder.encode(state.getProprioceptionInput());
        }
        
        // 2. 拼接多模态特征
        NdArray concatenatedFeatures = concatenateFeatures(
            visionFeatures, 
            languageFeatures, 
            proprioFeatures
        );
        
        // 3. 跨模态融合
        Variable fusedVar = transformerCore.fuse(new Variable(concatenatedFeatures));
        NdArray fusedFeatures = fusedVar.getValue();
        
        // 保存融合特征到状态
        state.setFusedFeatures(fusedFeatures);
        
        // 4. 解码动作
        VLAAction action = actionDecoder.decode(fusedFeatures);
        
        // 5. 生成语言反馈
        String feedback = feedbackGenerator.generateFeedback(
            action.getActionType(), 
            action.getConfidence()
        );
        action.setLanguageFeedback(feedback);
        
        return action;
    }
    
    /**
     * 拼接多模态特征
     */
    private NdArray concatenateFeatures(NdArray vision, NdArray language, NdArray proprio) {
        int visionLen = vision.getShape().getDimension(0);
        int langLen = language.getShape().getDimension(0);
        int totalLen = visionLen + langLen;
        
        if (proprio != null) {
            totalLen += proprio.getShape().getDimension(0);
        }
        
        float[][] concatenated = new float[totalLen][hiddenDim];
        
        // 复制视觉特征
        for (int i = 0; i < visionLen; i++) {
            for (int j = 0; j < hiddenDim; j++) {
                concatenated[i][j] = vision.get(i * hiddenDim + j);
            }
        }
        
        // 复制语言特征
        for (int i = 0; i < langLen; i++) {
            for (int j = 0; j < hiddenDim; j++) {
                concatenated[visionLen + i][j] = language.get(i * hiddenDim + j);
            }
        }
        
        // 复制本体感知特征
        if (proprio != null) {
            int proprioLen = proprio.getShape().getDimension(0);
            for (int i = 0; i < proprioLen; i++) {
                for (int j = 0; j < hiddenDim; j++) {
                    concatenated[visionLen + langLen + i][j] = proprio.get(i * hiddenDim + j);
                }
            }
        }
        
        return NdArray.of(concatenated);
    }
    
    /**
     * 获取模型参数数量
     */
    public int getParameterCount() {
        int count = 0;
        // 简化计算
        count += hiddenDim * hiddenDim * numLayers * 4; // Transformer参数
        count += hiddenDim * actionDim; // 解码器参数
        return count;
    }
    
    /**
     * 打印模型信息
     */
    public void printModelInfo() {
        System.out.println("\n========== VLA Agent Model Info ==========");
        System.out.println("Architecture: Vision-Language-Action Transformer");
        System.out.println("Hidden Dimension: " + hiddenDim);
        System.out.println("Attention Heads: " + numHeads);
        System.out.println("Transformer Layers: " + numLayers);
        System.out.println("Action Dimension: " + actionDim);
        System.out.println("Estimated Parameters: " + getParameterCount());
        System.out.println("==========================================\n");
    }
    
    /**
     * 批处理预测
     * 
     * @param states 状态列表
     * @return 动作列表
     */
    public java.util.List<VLAAction> batchPredict(java.util.List<VLAState> states) {
        java.util.List<VLAAction> actions = new java.util.ArrayList<>();
        for (VLAState state : states) {
            actions.add(predict(state));
        }
        return actions;
    }
    
    /**
     * 冻结编码器（微调时使用）
     */
    public void freezeEncoders() {
        // TODO: 实现参数冻结
        System.out.println("Encoders frozen (not fully implemented)");
    }
    
    /**
     * 解冻所有层
     */
    public void unfreezeAll() {
        // TODO: 实现参数解冻
        System.out.println("All layers unfrozen (not fully implemented)");
    }
    
    /**
     * 保存模型
     * 
     * @param filepath 文件路径
     */
    public void save(String filepath) {
        System.out.println("Saving model to: " + filepath);
        // TODO: 实现模型序列化
    }
    
    /**
     * 加载模型
     * 
     * @param filepath 文件路径
     * @return 加载的智能体
     */
    public static VLAAgent load(String filepath) {
        System.out.println("Loading model from: " + filepath);
        // TODO: 实现模型反序列化
        // 这里返回一个默认实例作为占位符
        return new VLAAgent(768, 8, 6, 7);
    }
}
