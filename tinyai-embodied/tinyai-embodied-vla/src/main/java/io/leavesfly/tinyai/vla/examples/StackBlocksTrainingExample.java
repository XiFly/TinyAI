package io.leavesfly.tinyai.vla.examples;

import io.leavesfly.tinyai.vla.VLAAgent;
import io.leavesfly.tinyai.vla.env.RobotEnvironment;
import io.leavesfly.tinyai.vla.env.SimpleRobotEnv;
import io.leavesfly.tinyai.vla.env.TaskScenario;
import io.leavesfly.tinyai.vla.learning.BehaviorCloningLearner;
import io.leavesfly.tinyai.vla.model.TaskConfig;
import io.leavesfly.tinyai.vla.model.VLAAction;
import io.leavesfly.tinyai.vla.model.VLAState;

/**
 * StackBlocksä»»åŠ¡è®­ç»ƒç¤ºä¾‹
 * 
 * å †å æ–¹å—ä»»åŠ¡æ˜¯æ¯”PickAndPlaceæ›´å¤æ‚çš„ä»»åŠ¡ï¼Œéœ€è¦ï¼š
 * 1. ç²¾ç¡®çš„è§†è§‰æ„ŸçŸ¥ï¼ˆåˆ¤æ–­æ–¹å—ä½ç½®å’Œç¨³å®šæ€§ï¼‰
 * 2. åºåˆ—åŒ–å†³ç­–ï¼ˆå…ˆæ”¾åº•å±‚ï¼Œå†æ”¾ä¸Šå±‚ï¼‰
 * 3. ç»†è‡´çš„åŠ›æ§åˆ¶ï¼ˆé¿å…æ¨å€’å·²å †å çš„æ–¹å—ï¼‰
 * 
 * æœ¬ç¤ºä¾‹å±•ç¤ºå¦‚ä½•ä½¿ç”¨è¯¾ç¨‹å­¦ä¹ ï¼ˆCurriculum Learningï¼‰ç­–ç•¥
 * ä»ç®€å•åˆ°å¤æ‚é€æ­¥è®­ç»ƒæ™ºèƒ½ä½“ã€‚
 * 
 * @author TinyAI Team
 * @version 1.0
 */
public class StackBlocksTrainingExample {
    
    // æ¨¡å‹é…ç½®
    private static final int HIDDEN_DIM = 768;
    private static final int NUM_HEADS = 8;
    private static final int NUM_LAYERS = 6;
    private static final int ACTION_DIM = 7;
    
    // è¯¾ç¨‹å­¦ä¹ é…ç½®
    private static final int[] CURRICULUM_BLOCKS = {2, 3, 4}; // ä»2ä¸ªæ–¹å—å¼€å§‹ï¼Œé€æ¸å¢åŠ åˆ°4ä¸ª
    private static final int[] CURRICULUM_EPISODES = {30, 50, 70}; // æ¯ä¸ªé˜¶æ®µçš„è®­ç»ƒå›åˆæ•°
    
    public static void main(String[] args) {
        printHeader();
        
        try {
            // åˆ›å»ºæ™ºèƒ½ä½“
            VLAAgent agent = createAgent();
            
            // è¯¾ç¨‹å­¦ä¹ è®­ç»ƒ
            curriculumLearning(agent);
            
            // æœ€ç»ˆè¯„ä¼°
            finalEvaluation(agent);
            
            printFooter();
            
        } catch (Exception e) {
            System.err.println("Training failed: " + e.getMessage());
            e.printStackTrace();
        }
    }
    
    /**
     * åˆ›å»ºVLAæ™ºèƒ½ä½“
     */
    private static VLAAgent createAgent() {
        System.out.println("=== Creating VLA Agent ===");
        
        VLAAgent agent = new VLAAgent(HIDDEN_DIM, NUM_HEADS, NUM_LAYERS, ACTION_DIM);
        
        System.out.println("âœ“ Agent created");
        agent.printModelInfo();
        System.out.println();
        
        return agent;
    }
    
    /**
     * è¯¾ç¨‹å­¦ä¹ è®­ç»ƒ
     * é€æ­¥å¢åŠ ä»»åŠ¡éš¾åº¦ï¼Œå¸®åŠ©æ¨¡å‹æ›´å¥½åœ°å­¦ä¹ 
     */
    private static void curriculumLearning(VLAAgent agent) {
        System.out.println("=== Curriculum Learning ===");
        System.out.println("Training Strategy: Start simple, then increase difficulty\n");
        
        for (int stage = 0; stage < CURRICULUM_BLOCKS.length; stage++) {
            int numBlocks = CURRICULUM_BLOCKS[stage];
            int episodes = CURRICULUM_EPISODES[stage];
            
            System.out.println("â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”");
            System.out.printf("â”‚ Stage %d: Stacking %d Blocks            â”‚%n", stage + 1, numBlocks);
            System.out.println("â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜");
            
            // åˆ›å»ºå¯¹åº”éš¾åº¦çš„ç¯å¢ƒ
            RobotEnvironment env = createEnvironment(numBlocks);
            
            // è®­ç»ƒè¯¥é˜¶æ®µ
            trainStage(agent, env, episodes, numBlocks);
            
            // è¯„ä¼°è¯¥é˜¶æ®µ
            evaluateStage(agent, env, numBlocks);
            
            env.close();
            System.out.println();
        }
        
        System.out.println("âœ“ Curriculum Learning Completed\n");
    }
    
    /**
     * åˆ›å»ºæŒ‡å®šéš¾åº¦çš„ç¯å¢ƒ
     */
    private static RobotEnvironment createEnvironment(int numBlocks) {
        TaskConfig taskConfig = new TaskConfig();
        taskConfig.setTaskName("Stack " + numBlocks + " Blocks");
        taskConfig.setTaskDescription(TaskScenario.STACK_BLOCKS.getDescription());
        taskConfig.setMaxSteps(100 + numBlocks * 20); // æ›´å¤šæ–¹å—éœ€è¦æ›´å¤šæ­¥æ•°
        taskConfig.setSuccessReward(100.0 * numBlocks); // å¥–åŠ±éšéš¾åº¦å¢åŠ 
//        taskConfig.setStepPenalty(-0.1);
        taskConfig.setRender(false);
        
        // è®¾ç½®ç‰¹å®šå‚æ•°
//        taskConfig.addParameter("num_blocks", numBlocks);
        
        return new SimpleRobotEnv(taskConfig);
    }
    
    /**
     * è®­ç»ƒæŸä¸ªé˜¶æ®µ
     */
    private static void trainStage(VLAAgent agent, RobotEnvironment env, 
                                    int episodes, int numBlocks) {
        System.out.println("Training Phase:");
        System.out.println("  Episodes: " + episodes);
        System.out.println("  Learning Rate: 0.001");
        System.out.println();
        
        BehaviorCloningLearner learner = new BehaviorCloningLearner(0.001);
        
        double totalReward = 0.0;
        int successCount = 0;
        
        for (int episode = 1; episode <= episodes; episode++) {
            double episodeReward = learner.trainEpisode(agent, env);
            totalReward += episodeReward;
            
            if (episodeReward > 80.0 * numBlocks) {
                successCount++;
            }
            
            if (episode % 10 == 0) {
                double avgReward = totalReward / episode;
                double successRate = (double) successCount / episode * 100;
                
                System.out.printf("  Episode %3d - Avg Reward: %6.2f | Success Rate: %5.1f%%%n",
                    episode, avgReward, successRate);
            }
        }
        
        System.out.println();
    }
    
    /**
     * è¯„ä¼°é˜¶æ®µæ€§èƒ½
     */
    private static void evaluateStage(VLAAgent agent, RobotEnvironment env, int numBlocks) {
        System.out.println("Stage Evaluation:");
        
        int evalEpisodes = 10;
        double totalReward = 0.0;
        int successCount = 0;
        int perfectStackCount = 0;
        
        for (int i = 0; i < evalEpisodes; i++) {
            VLAState state = env.reset();
            double episodeReward = 0.0;
            int blocksStacked = 0;
            
            for (int step = 0; step < 200; step++) {
                VLAAction action = agent.predict(state);
                RobotEnvironment.EnvironmentStep envStep = env.step(action);
                
                episodeReward += envStep.getReward();
                
                // æ£€æŸ¥å †å è¿›åº¦
                if (envStep.getInfo() != null) {
                    Object stacked = envStep.getInfo().get("blocks_stacked");
                    if (stacked instanceof Integer) {
                        blocksStacked = Math.max(blocksStacked, (Integer) stacked);
                    }
                }
                
                if (envStep.isDone()) {
                    break;
                }
                
                state = envStep.getNextState();
            }
            
            totalReward += episodeReward;
            
            if (blocksStacked >= numBlocks - 1) {
                successCount++;
            }
            if (blocksStacked == numBlocks) {
                perfectStackCount++;
            }
        }
        
        double avgReward = totalReward / evalEpisodes;
        double successRate = (double) successCount / evalEpisodes * 100;
        double perfectRate = (double) perfectStackCount / evalEpisodes * 100;
        
        System.out.printf("  Average Reward: %.2f%n", avgReward);
        System.out.printf("  Success Rate: %.1f%% (>=%d blocks)%n", successRate, numBlocks - 1);
        System.out.printf("  Perfect Rate: %.1f%% (all %d blocks)%n", perfectRate, numBlocks);
        System.out.println();
    }
    
    /**
     * æœ€ç»ˆç»¼åˆè¯„ä¼°
     */
    private static void finalEvaluation(VLAAgent agent) {
        System.out.println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
        System.out.println("â•‘        Final Evaluation                â•‘");
        System.out.println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        System.out.println();
        
        // åœ¨æ‰€æœ‰éš¾åº¦ä¸‹æµ‹è¯•
        for (int numBlocks : CURRICULUM_BLOCKS) {
            System.out.println("Testing with " + numBlocks + " blocks:");
            
            RobotEnvironment env = createEnvironment(numBlocks);
            
            double totalReward = 0.0;
            int successCount = 0;
            
            for (int i = 0; i < 20; i++) {
                VLAState state = env.reset();
                double episodeReward = 0.0;
                
                for (int step = 0; step < 200; step++) {
                    VLAAction action = agent.predict(state);
                    RobotEnvironment.EnvironmentStep envStep = env.step(action);
                    
                    episodeReward += envStep.getReward();
                    
                    if (envStep.isDone()) {
                        break;
                    }
                    
                    state = envStep.getNextState();
                }
                
                totalReward += episodeReward;
                
                if (episodeReward > 80.0 * numBlocks) {
                    successCount++;
                }
            }
            
            double avgReward = totalReward / 20;
            double successRate = (double) successCount / 20 * 100;
            
            System.out.printf("  Average Reward: %.2f | Success Rate: %.1f%%%n", 
                avgReward, successRate);
            
            env.close();
        }
        
        System.out.println();
    }
    
    // ==================== ç•Œé¢è¾“å‡º ====================
    
    private static void printHeader() {
        System.out.println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
        System.out.println("â•‘       TinyAI VLA - StackBlocks Training Example           â•‘");
        System.out.println("â•‘          Curriculum Learning for Complex Tasks            â•‘");
        System.out.println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
        System.out.println();
    }
    
    private static void printFooter() {
        System.out.println("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—");
        System.out.println("â•‘              Training Completed Successfully!             â•‘");
        System.out.println("â•‘         Your agent can now stack blocks! ğŸ“¦ğŸ“¦ğŸ“¦            â•‘");
        System.out.println("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•");
    }
}
