# TinyAIï¼šå…¨æ ˆå¼è½»é‡çº§AIæ¡†æ¶

> å±±æ³½ è‘—
> 
> ä¸€ä¸ªå®Œå…¨ç”¨Javaå®ç°çš„å…¨æ ˆå¼è½»é‡çº§AIæ¡†æ¶ï¼ŒTinyAI IS ALL YOU NEEDã€‚

## å‰è¨€ï¼šä¸ºä»€ä¹ˆè¦ç”¨JavaåšAIï¼Ÿ

åœ¨AIé¢†åŸŸï¼ŒPythonæ— ç–‘æ˜¯å½“å‰çš„ä¸»æµè¯­è¨€ã€‚ä½†å¯¹äºJavaå¼€å‘è€…æ¥è¯´ï¼Œè¦æƒ³æ·±å…¥ç†è§£AIç®—æ³•çš„æœ¬è´¨ï¼Œæˆ–è€…åœ¨ä¼ä¸šçº§Javaåº”ç”¨ä¸­é›†æˆAIèƒ½åŠ›ï¼Œå¾€å¾€é¢ä¸´ç€æŠ€æœ¯æ ˆå‰²è£‚çš„å›°æ‰°ã€‚TinyAIé¡¹ç›®æ­£æ˜¯åœ¨è¿™æ ·çš„èƒŒæ™¯ä¸‹åº”è¿è€Œç”Ÿâ€”â€”ç”¨çº¯Javaè¯­è¨€ï¼Œä»æœ€åŸºç¡€çš„æ•°å­¦è¿ç®—å¼€å§‹ï¼Œä¸€æ­¥æ­¥æ„å»ºèµ·ä¸€ä¸ªåŠŸèƒ½å®Œæ•´çš„AIæ¡†æ¶ã€‚

**TinyAIçš„æ ¸å¿ƒç†å¿µï¼š**
- ğŸ¯ **æ•™è‚²å‹å¥½**ï¼šæ¸…æ™°çš„ä»£ç ç»“æ„ï¼Œè¯¦å°½çš„ä¸­æ–‡æ³¨é‡Šï¼Œè®©æ¯ä¸€è¡Œä»£ç éƒ½èƒ½è¯´è¯
- ğŸ§© **æ¨¡å—åŒ–è®¾è®¡**ï¼šåƒæ­ä¹é«˜ä¸€æ ·ç»„åˆAIç»„ä»¶ï¼Œæ¯ä¸ªæ¨¡å—èŒè´£æ˜ç¡®
- ğŸš€ **ç”Ÿäº§çº§åˆ«**ï¼šä¸ä»…æ˜¯ç©å…·ï¼Œæ›´æ˜¯å¯ä»¥æŠ•å…¥å®é™…åº”ç”¨çš„æ¡†æ¶
- ğŸ”§ **é›¶å¤–éƒ¨ä¾èµ–**ï¼šæ ¸å¿ƒè®¡ç®—å¼•æ“å®Œå…¨è‡ªä¸»å®ç°ï¼Œä¸ä¾èµ–ä»»ä½•ç¬¬ä¸‰æ–¹AIåº“

## ç¬¬ä¸€ç« ï¼šæ¶æ„ä¹‹ç¾â€”â€”åˆ†å±‚è®¾è®¡çš„æ™ºæ…§

### 1.1 ä»"æ­ç§¯æœ¨"çš„è§’åº¦ç†è§£TinyAI

æƒ³è±¡ä¸€ä¸‹ï¼Œå¦‚æœè¦å»ºé€ ä¸€åº§æ‘©å¤©å¤§æ¥¼ï¼Œæˆ‘ä»¬ä¼šæ€ä¹ˆåšï¼Ÿé¦–å…ˆéœ€è¦åšå®çš„åœ°åŸºï¼Œç„¶åæ˜¯æ‰¿é‡ç»“æ„ï¼Œå†æ˜¯å„ç§åŠŸèƒ½æ¨¡å—ï¼Œæœ€åæ˜¯å¤–è§‚è£…é¥°ã€‚TinyAIçš„æ¶æ„è®¾è®¡æ­£æ˜¯éµå¾ªäº†è¿™æ ·çš„æ€è·¯ï¼š

```mermaid
graph TB
    subgraph "ğŸ¯ åº”ç”¨å±•ç¤ºå±‚"
        App1[æ™ºèƒ½å®¢æœç³»ç»Ÿ]
        App2[ä»£ç ç”ŸæˆåŠ©æ‰‹] 
        App3[æ–‡æ¡£æ™ºèƒ½å¤„ç†]
        App4[è‚¡ç¥¨é¢„æµ‹åˆ†æ]
    end
    
    subgraph "ğŸ¤– æ™ºèƒ½ä½“ç³»ç»Ÿå±‚"
        Agent1[tinyai-agent-base<br/>åŸºç¡€æ™ºèƒ½ä½“æ¡†æ¶]
        Agent2[tinyai-agent-rag<br/>æ£€ç´¢å¢å¼ºç”Ÿæˆ]
        Agent3[tinyai-agent-multi<br/>å¤šæ™ºèƒ½ä½“åä½œ]
        Agent4[tinyai-agent-evol<br/>è‡ªè¿›åŒ–æ™ºèƒ½ä½“]
        Agent5[tinyai-agent-pattern<br/>è®¤çŸ¥æ¨¡å¼åº“]
        Agent6[tinyai-agent-cursor<br/>AIç¼–ç å…‰æ ‡]
        Agent7[tinyai-agent-research<br/>æ·±åº¦ç ”ç©¶æ™ºèƒ½ä½“]
    end
    
    subgraph "ğŸ§  å¤§è¯­è¨€æ¨¡å‹å±‚"
        Model1[tinyai-model-gpt<br/>GPTç³»åˆ—æ¨¡å‹]
        Model2[tinyai-model-deepseek<br/>DeepSeekæ¨¡å‹]
        Model3[tinyai-model-qwen<br/>Qwen3æ¨¡å‹]
        Model4[tinyai-model-lora<br/>LoRAå¾®è°ƒ]
        Model5[tinyai-model-moe<br/>æ··åˆä¸“å®¶æ¨¡å‹]
    end
    
    subgraph "ğŸš€ æ·±åº¦å­¦ä¹ æ¡†æ¶å±‚"
        DL1[tinyai-deeplearning-ml<br/>æœºå™¨å­¦ä¹ æ ¸å¿ƒ]
        DL2[tinyai-deeplearning-nnet<br/>ç¥ç»ç½‘ç»œå±‚]
        DL3[tinyai-deeplearning-rl<br/>å¼ºåŒ–å­¦ä¹ æ¨¡å—]
        DL4[tinyai-deeplearning-case<br/>åº”ç”¨ç¤ºä¾‹é›†]
    end
    
    subgraph "âš¡ è®¡ç®—å¼•æ“å±‚"
        Engine1[tinyai-deeplearning-func<br/>è‡ªåŠ¨å¾®åˆ†å¼•æ“]
    end
    
    subgraph "ğŸ§® æ•°å€¼åŸºç¡€å±‚"
        Base1[tinyai-deeplearning-ndarr<br/>å¤šç»´æ•°ç»„åº“]
    end
    
    App1 --> Agent1
    App2 --> Agent6
    App3 --> Agent2
    App4 --> Model1
    
    Agent1 --> Model1
    Agent2 --> DL1
    Agent3 --> DL1
    
    Model1 --> DL1
    Model2 --> DL1
    Model3 --> DL1
    
    DL1 --> DL2
    DL2 --> Engine1
    DL3 --> Engine1
    
    Engine1 --> Base1
```

è¿™ç§åˆ†å±‚è®¾è®¡çš„å¥½å¤„æ˜¾è€Œæ˜“è§ï¼š
- **åº•å±‚ç¨³å®š**ï¼šæ•°å€¼è®¡ç®—å’Œè‡ªåŠ¨å¾®åˆ†å¼•æ“ä¸ºæ•´ä¸ªç³»ç»Ÿæä¾›å¯é åŸºç¡€
- **ä¸­å±‚çµæ´»**ï¼šç¥ç»ç½‘ç»œå±‚æä¾›ä¸°å¯Œçš„ç»„ä»¶åº“ï¼Œæ”¯æŒå„ç§ç½‘ç»œæ¶æ„
- **ä¸Šå±‚å¼€æ”¾**ï¼šæ™ºèƒ½ä½“å’Œæ¨¡å‹å±‚é¢å‘åº”ç”¨ï¼Œæ”¯æŒå¿«é€Ÿå¼€å‘

### 1.2 æ ¸å¿ƒæ¨¡å—ï¼š16ä¸ªç²¾å¿ƒè®¾è®¡çš„ç»„ä»¶

TinyAIæ€»å…±åŒ…å«16ä¸ªæ ¸å¿ƒæ¨¡å—ï¼Œæ¯ä¸ªæ¨¡å—éƒ½æœ‰å…¶ç‹¬ç‰¹çš„èŒè´£ï¼š

| å±‚æ¬¡ | æ¨¡å— | æ ¸å¿ƒåŠŸèƒ½ | è®¾è®¡ç†å¿µ |
|------|------|----------|----------|
| **åŸºç¡€å±‚** | `tinyai-deeplearning-ndarr` | å¤šç»´æ•°ç»„è®¡ç®— | é«˜æ€§èƒ½æ•°å€¼è¿ç®—çš„åŸºçŸ³ |
| **åŸºç¡€å±‚** | `tinyai-deeplearning-func` | è‡ªåŠ¨å¾®åˆ†å¼•æ“ | æ·±åº¦å­¦ä¹ çš„"é­”æ³•"æ ¸å¿ƒ |
| **ç½‘ç»œå±‚** | `tinyai-deeplearning-nnet` | ç¥ç»ç½‘ç»œç»„ä»¶ | ä¸°å¯Œçš„ç½‘ç»œå±‚ç§¯æœ¨ |
| **æ¡†æ¶å±‚** | `tinyai-deeplearning-ml` | æœºå™¨å­¦ä¹ æ ¸å¿ƒ | è®­ç»ƒã€ä¼˜åŒ–ã€è¯„ä¼°ä¸€ç«™å¼ |
| **åº”ç”¨å±‚** | `tinyai-agent-*` (6ä¸ªæ¨¡å—) | æ™ºèƒ½ä½“ç³»ç»Ÿ | ä»åŸºç¡€åˆ°è¿›åŒ–çš„å®Œæ•´æ™ºèƒ½ä½“ç”Ÿæ€ |
| **æ¨¡å‹å±‚** | `tinyai-model-*` (5ä¸ªæ¨¡å—) | å¤§è¯­è¨€æ¨¡å‹ | GPTç³»åˆ—ã€DeepSeekã€Qwenç­‰å‰æ²¿æ¨¡å‹ |

## ç¬¬äºŒç« ï¼šä»é›¶å¼€å§‹çš„æ•°å­¦ä¹‹æ—…

### 2.1 å¤šç»´æ•°ç»„ï¼šä¸€åˆ‡è®¡ç®—çš„èµ·ç‚¹

åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œæ•°æ®éƒ½æ˜¯ä»¥å¼ é‡ï¼ˆå¤šç»´æ•°ç»„ï¼‰çš„å½¢å¼å­˜åœ¨ã€‚TinyAIçš„`NdArray`æ¥å£è®¾è®¡å¾—éå¸¸ä¼˜é›…ï¼š

```java
// åˆ›å»ºæ•°ç»„çš„å¤šç§æ–¹å¼
NdArray a = NdArray.of(new float[][]{{1, 2}, {3, 4}});     // ä»äºŒç»´æ•°ç»„åˆ›å»º
NdArray b = NdArray.zeros(Shape.of(2, 3));                 // åˆ›å»º2x3çš„é›¶çŸ©é˜µ
NdArray c = NdArray.randn(Shape.of(100, 50));              // åˆ›å»ºéšæœºæ­£æ€åˆ†å¸ƒçŸ©é˜µ

// ä¸°å¯Œçš„æ•°å­¦è¿ç®—
NdArray result = a.add(b)           // çŸ©é˜µåŠ æ³•
                 .mul(c)            // å¯¹åº”å…ƒç´ ç›¸ä¹˜
                 .dot(d)            // çŸ©é˜µä¹˜æ³•
                 .sigmoid()         // Sigmoidæ¿€æ´»å‡½æ•°
                 .transpose();      // è½¬ç½®
```

**è®¾è®¡äº®ç‚¹ï¼š**
- **é“¾å¼è°ƒç”¨**ï¼šæ”¯æŒæµç•…çš„é“¾å¼æ“ä½œï¼Œä»£ç å¯è¯»æ€§æä½³
- **å½¢çŠ¶å®‰å…¨**ï¼šç¼–è¯‘æ—¶å’Œè¿è¡Œæ—¶çš„åŒé‡å½¢çŠ¶æ£€æŸ¥ï¼Œé¿å…ç»´åº¦é”™è¯¯
- **å†…å­˜ä¼˜åŒ–**ï¼šæ™ºèƒ½çš„å†…å­˜ç®¡ç†ï¼Œé¿å…ä¸å¿…è¦çš„æ•°æ®æ‹·è´

### 2.2 è‡ªåŠ¨å¾®åˆ†ï¼šæ·±åº¦å­¦ä¹ çš„"é­”æ³•"æ ¸å¿ƒ


```mermaid
graph TD
    subgraph "è®¡ç®—å›¾æ„å»ºè¿‡ç¨‹"
        A[è¾“å…¥å˜é‡ x, y] --> B[å‰å‘è®¡ç®—: z = x*y + xÂ²]
        B --> C[æ„å»ºè®¡ç®—å›¾]
        C --> D[åå‘ä¼ æ’­: è‡ªåŠ¨è®¡ç®—æ¢¯åº¦]
        D --> E[è¾“å‡º: dz/dx, dz/dy]
    end
    
    subgraph "æŠ€æœ¯å®ç°ç‰¹ç‚¹"
        F[åŠ¨æ€è®¡ç®—å›¾] --> G[æ”¯æŒæ¡ä»¶åˆ†æ”¯]
        F --> H[æ”¯æŒå¾ªç¯ç»“æ„]
        I[é€’å½’ä¸è¿­ä»£] --> J[æ·±åº¦ç½‘ç»œæ”¯æŒ]
        I --> K[æ ˆæº¢å‡ºé¿å…]
        L[æ¢¯åº¦ç´¯ç§¯] --> M[å¤æ‚ç½‘ç»œæ”¯æŒ]
        L --> N[å‚æ•°å…±äº«å¤„ç†]
    end
```

è‡ªåŠ¨å¾®åˆ†æ˜¯æ·±åº¦å­¦ä¹ çš„æ ¸å¿ƒæŠ€æœ¯ã€‚TinyAIçš„`Variable`ç±»é€šè¿‡è®¡ç®—å›¾è‡ªåŠ¨è¿½è¸ªæ“ä½œå†å²ï¼š

```java
// æ„å»ºä¸€ä¸ªç®€å•çš„è®¡ç®—å›¾
Variable x = new Variable(NdArray.of(2.0f), "x");
Variable y = new Variable(NdArray.of(3.0f), "y");

// æ­£å‘ä¼ æ’­ï¼šæ„å»ºè®¡ç®—å›¾
Variable z = x.mul(y).add(x.squ());  // z = x*y + xÂ²

// åå‘ä¼ æ’­ï¼šè‡ªåŠ¨è®¡ç®—æ¢¯åº¦
z.backward();

System.out.println("dz/dx = " + x.getGrad().getNumber());  // è¾“å‡ºï¼šdz/dx = 7.0
System.out.println("dz/dy = " + y.getGrad().getNumber());  // è¾“å‡ºï¼šdz/dy = 2.0
```

**æŠ€æœ¯å®ç°çš„ç²¾å¦™ä¹‹å¤„ï¼š**

1. **åŠ¨æ€è®¡ç®—å›¾**ï¼šæ¯æ¬¡è¿ç®—éƒ½ä¼šåŠ¨æ€æ„å»ºè®¡ç®—å›¾ï¼Œæ”¯æŒæ¡ä»¶åˆ†æ”¯å’Œå¾ªç¯
2. **é€’å½’ä¸è¿­ä»£**ï¼šæä¾›ä¸¤ç§åå‘ä¼ æ’­å®ç°ï¼Œé€‚åº”ä¸åŒåœºæ™¯éœ€æ±‚
3. **æ¢¯åº¦ç´¯ç§¯**ï¼šæ”¯æŒæ¢¯åº¦çš„è‡ªåŠ¨ç´¯ç§¯ï¼Œå¤„ç†å¤æ‚çš„ç½‘ç»œç»“æ„

```java
public void backward() {
    if (!requireGrad) return;
    
    // åˆå§‹åŒ–æ¢¯åº¦ä¸º1ï¼ˆé“¾å¼æ³•åˆ™çš„èµ·ç‚¹ï¼‰
    if (Objects.isNull(grad)) {
        setGrad(NdArray.ones(this.getValue().getShape()));
    }
    
    Function creator = this.creator;
    if (creator != null) {
        Variable[] inputs = creator.getInputs();
        List<NdArray> grads = creator.backward(grad);  // è®¡ç®—è¾“å…¥çš„æ¢¯åº¦
        
        // é€’å½’è®¡ç®—æ¯ä¸ªè¾“å…¥å˜é‡çš„æ¢¯åº¦
        for (int i = 0; i < inputs.length; i++) {
            Variable input = inputs[i];
            // æ¢¯åº¦ç´¯ç§¯ï¼šæ”¯æŒå˜é‡è¢«å¤šæ¬¡ä½¿ç”¨çš„æƒ…å†µ
            if (input.getGrad() != null) {
                input.setGrad(input.getGrad().add(grads.get(i)));
            } else {
                input.setGrad(grads.get(i));
            }
            input.backward();  // é€’å½’è°ƒç”¨
        }
    }
}
```

## ç¬¬ä¸‰ç« ï¼šç¥ç»ç½‘ç»œçš„ç§¯æœ¨ä¸–ç•Œ

### 3.1 Layerä¸Blockï¼šç»„åˆçš„è‰ºæœ¯

TinyAIé‡‡ç”¨äº†ç±»ä¼¼PyTorchçš„Layer-Blockè®¾è®¡æ¨¡å¼ï¼š

```mermaid
graph TB
    subgraph "Layerå±‚è®¾è®¡"
        L1[LinearLayer<br/>çº¿æ€§å˜æ¢]
        L2[ReluLayer<br/>æ¿€æ´»å‡½æ•°]
        L3[DropoutLayer<br/>æ­£åˆ™åŒ–]
        L4[BatchNormLayer<br/>æ‰¹æ ‡å‡†åŒ–]
    end
    
    subgraph "Blockå—ç»„åˆ"
        B1[SequentialBlock<br/>é¡ºåºè¿æ¥]
        B2[ResidualBlock<br/>æ®‹å·®è¿æ¥]
        B3[AttentionBlock<br/>æ³¨æ„åŠ›æœºåˆ¶]
        B4[TransformerBlock<br/>Transformerå—]
    end
    
    subgraph "Modelæ¨¡å‹å°è£…"
        M1[å‚æ•°ç®¡ç†]
        M2[è®­ç»ƒ/æ¨ç†æ¨¡å¼]
        M3[åºåˆ—åŒ–æ”¯æŒ]
        M4[çŠ¶æ€æ§åˆ¶]
    end
    
    L1 --> B1
    L2 --> B1
    L3 --> B1
    L4 --> B1
    
    B1 --> M1
    B2 --> M1
    B3 --> M1
    B4 --> M1
```

```java
// Layerï¼šæœ€åŸºç¡€çš„è®¡ç®—å•å…ƒ
public abstract class Layer {
    protected Map<String, Variable> parameters = new HashMap<>();
    
    public abstract Variable layerForward(Variable... inputs);
    
    // å‚æ•°ç®¡ç†
    protected void addParameter(String name, NdArray value) {
        parameters.put(name, new Variable(value, name));
    }
}

// Blockï¼šLayerçš„ç»„åˆå®¹å™¨
public abstract class Block {
    protected List<Layer> layers = new ArrayList<>();
    
    public abstract Variable blockForward(Variable... inputs);
    
    // æ”¯æŒåµŒå¥—ç»„åˆ
    public void addBlock(Block subBlock) {
        // å°†å­Blockçš„Layeræ·»åŠ åˆ°å½“å‰Block
    }
}
```

**å®é™…åº”ç”¨ç¤ºä¾‹ï¼š**

```java
// æ„å»ºä¸€ä¸ªå¤šå±‚æ„ŸçŸ¥æœº
MlpBlock mlp = new MlpBlock("classifier", 784, new int[]{128, 64, 10});

// æ„å»ºä¸€ä¸ªå®Œæ•´çš„ç¥ç»ç½‘ç»œ
SequentialBlock network = new SequentialBlock("mnist_net");
network.addLayer(new FlattenLayer("flatten"))           // å±•å¹³å±‚
       .addLayer(new LinearLayer("fc1", 784, 128))      // å…¨è¿æ¥å±‚1
       .addLayer(new ReluLayer("relu1"))                // ReLUæ¿€æ´»
       .addLayer(new LinearLayer("fc2", 128, 64))       // å…¨è¿æ¥å±‚2
       .addLayer(new ReluLayer("relu2"))                // ReLUæ¿€æ´»
       .addLayer(new LinearLayer("fc3", 64, 10))        // è¾“å‡ºå±‚
       .addLayer(new SoftmaxLayer("softmax"));          // Softmax
```

### 3.2 ç°ä»£ç½‘ç»œæ¶æ„çš„å®ç°

TinyAIä¸ä»…æ”¯æŒåŸºç¡€çš„ç¥ç»ç½‘ç»œï¼Œè¿˜å®ç°äº†ç°ä»£çš„å…ˆè¿›æ¶æ„ï¼š

**Transformeræ¶æ„ï¼š**
```java
public class TransformerBlock extends Block {
    private MultiHeadAttentionLayer attention;
    private FeedForwardLayer feedForward;
    private LayerNormalizationLayer norm1, norm2;
    
    @Override
    public Variable blockForward(Variable... inputs) {
        Variable input = inputs[0];
        
        // Self-Attention + æ®‹å·®è¿æ¥
        Variable attnOut = norm1.layerForward(input);
        attnOut = attention.layerForward(attnOut, attnOut, attnOut);
        Variable residual1 = input.add(attnOut);
        
        // Feed-Forward + æ®‹å·®è¿æ¥
        Variable ffOut = norm2.layerForward(residual1);
        ffOut = feedForward.layerForward(ffOut);
        return residual1.add(ffOut);
    }
}
```

**LSTMå¾ªç¯ç½‘ç»œï¼š**
```java
public class LstmLayer extends Layer {
    @Override
    public Variable layerForward(Variable... inputs) {
        Variable x = inputs[0];
        Variable h = inputs[1];  // éšè—çŠ¶æ€
        Variable c = inputs[2];  // ç»†èƒçŠ¶æ€
        
        // é—å¿˜é—¨
        Variable f = sigmoid(linear(concat(x, h), Wf).add(bf));
        // è¾“å…¥é—¨
        Variable i = sigmoid(linear(concat(x, h), Wi).add(bi));
        // å€™é€‰å€¼
        Variable g = tanh(linear(concat(x, h), Wg).add(bg));
        // è¾“å‡ºé—¨
        Variable o = sigmoid(linear(concat(x, h), Wo).add(bo));
        
        // æ›´æ–°ç»†èƒçŠ¶æ€å’Œéšè—çŠ¶æ€
        Variable newC = f.mul(c).add(i.mul(g));
        Variable newH = o.mul(tanh(newC));
        
        return newH;
    }
}
```

## ç¬¬å››ç« ï¼šè®­ç»ƒçš„è‰ºæœ¯â€”â€”ä»æ•°æ®åˆ°æ™ºæ…§

```mermaid
graph LR
    A[ğŸ§® NdArray<br/>æ•°å€¼è®¡ç®—åŸºçŸ³] --> B[âš¡ Variable<br/>è‡ªåŠ¨å¾®åˆ†èŠ‚ç‚¹]
    B --> C[ğŸ§± Layer/Block<br/>ç½‘ç»œæ„å»ºç§¯æœ¨]
    C --> D[ğŸ¯ Model<br/>æ¨¡å‹ç”Ÿå‘½å‘¨æœŸ]
    D --> E[ğŸš€ Trainer<br/>æ™ºèƒ½è®­ç»ƒå™¨]
    
    A1[é«˜æ•ˆè®¡ç®—] -.-> A
    A2[å†…å­˜ä¼˜åŒ–] -.-> A
    A3[å¹¿æ’­æœºåˆ¶] -.-> A
    
    B1[è®¡ç®—å›¾æ„å»º] -.-> B
    B2[æ¢¯åº¦è‡ªåŠ¨ä¼ æ’­] -.-> B
    B3[åŠ¨æ€æ±‚å¯¼] -.-> B
    
    C1[ç»„åˆæ¨¡å¼] -.-> C
    C2[æ¨¡å—åŒ–è®¾è®¡] -.-> C
    C3[å±‚æ¬¡æŠ½è±¡] -.-> C
    
    D1[å‚æ•°ç®¡ç†] -.-> D
    D2[çŠ¶æ€æ§åˆ¶] -.-> D
    D3[åºåˆ—åŒ–æ”¯æŒ] -.-> D
    
    E1[å¹¶è¡Œè®­ç»ƒ] -.-> E
    E2[æ™ºèƒ½ç›‘æ§] -.-> E
    E3[è‡ªåŠ¨ä¼˜åŒ–] -.-> E
```

### 4.1 Trainerï¼šè®­ç»ƒè¿‡ç¨‹çš„æŒ‡æŒ¥å®¶

```mermaid
sequenceDiagram
    participant Data as ğŸ“Š æ•°æ®é›†
    participant Model as ğŸ§  æ¨¡å‹
    participant Loss as ğŸ“‰ æŸå¤±å‡½æ•°
    participant Optimizer as âš¡ ä¼˜åŒ–å™¨
    participant Monitor as ğŸ“ˆ ç›‘æ§å™¨
    
    Note over Data, Monitor: è®­ç»ƒå¾ªç¯å¼€å§‹
    Data->>Model: æ‰¹æ¬¡æ•°æ®è¾“å…¥
    Model->>Model: å‰å‘ä¼ æ’­
    Model->>Loss: é¢„æµ‹ç»“æœ
    Loss->>Loss: è®¡ç®—æŸå¤±å€¼
    Loss->>Model: åå‘ä¼ æ’­
    Model->>Optimizer: æ¢¯åº¦ä¿¡æ¯
    Optimizer->>Model: å‚æ•°æ›´æ–°
    Model->>Monitor: è®­ç»ƒæŒ‡æ ‡
    Monitor->>Monitor: è®°å½•å’Œå¯è§†åŒ–
    
    Note over Data, Monitor: è‡ªåŠ¨é‡å¤ç›´è‡³æ”¶æ•›
```

TinyAIçš„`Trainer`ç±»å°è£…äº†å®Œæ•´çš„è®­ç»ƒæµç¨‹ï¼Œè®©å¤æ‚çš„è®­ç»ƒè¿‡ç¨‹å˜å¾—ç®€å•ï¼š

```java
// åˆ›å»ºæ•°æ®é›†
DataSet trainData = new ArrayDataset(trainX, trainY);

// æ„å»ºæ¨¡å‹
Model model = new Model("mnist_classifier", mlpBlock);

// é…ç½®è®­ç»ƒå™¨ï¼ˆæ”¯æŒå¹¶è¡Œè®­ç»ƒï¼‰
Trainer trainer = new Trainer(
    epochs: 100,                          // è®­ç»ƒè½®æ•°
    monitor: new TrainingMonitor(),       // è®­ç»ƒç›‘æ§å™¨
    evaluator: new AccuracyEvaluator(),   // è¯„ä¼°å™¨
    useParallel: true,                    // å¯ç”¨å¹¶è¡Œè®­ç»ƒ
    threadCount: 4                        // çº¿ç¨‹æ•°
);

// åˆå§‹åŒ–è®­ç»ƒå™¨
trainer.init(trainData, model, 
            new MeanSquaredErrorLoss(),    // æŸå¤±å‡½æ•°
            new SgdOptimizer(0.01f));      // ä¼˜åŒ–å™¨

// å¼€å§‹è®­ç»ƒï¼ˆä¸€é”®å¼è®­ç»ƒï¼‰
trainer.train(showTrainingCurve: true);
```

**è®­ç»ƒè¿‡ç¨‹çš„æ ¸å¿ƒæµç¨‹ï¼š**

```java
public void train(boolean showCurve) {
    for (int epoch = 0; epoch < epochs; epoch++) {
        // 1. è®¾ç½®æ¨¡å‹ä¸ºè®­ç»ƒæ¨¡å¼
        model.setTraining(true);
        
        // 2. æ‰¹æ¬¡è®­ç»ƒ
        for (DataBatch batch : dataSet.getBatches()) {
            // 2.1 å‰å‘ä¼ æ’­
            Variable prediction = model.forward(batch.getInputs());
            
            // 2.2 è®¡ç®—æŸå¤±
            Variable loss = lossFunction.forward(prediction, batch.getTargets());
            
            // 2.3 æ¸…ç©ºæ¢¯åº¦
            model.clearGradients();
            
            // 2.4 åå‘ä¼ æ’­
            loss.backward();
            
            // 2.5 å‚æ•°æ›´æ–°
            optimizer.step(model.getParameters());
            
            // 2.6 è®°å½•è®­ç»ƒä¿¡æ¯
            monitor.recordTrainingStep(loss.getValue().getNumber());
        }
        
        // 3. æ¨¡å‹è¯„ä¼°
        if (epoch % 10 == 0) {
            float accuracy = evaluator.evaluate(model, validationData);
            monitor.recordEpoch(epoch, accuracy);
        }
    }
    
    // 4. å¯è§†åŒ–è®­ç»ƒæ›²çº¿
    if (showCurve) {
        monitor.plotTrainingCurve();
    }
}
```

### 4.2 å¹¶è¡Œè®­ç»ƒï¼šæ¦¨å¹²å¤šæ ¸æ€§èƒ½

TinyAIæ”¯æŒå¤šçº¿ç¨‹å¹¶è¡Œè®­ç»ƒï¼Œå……åˆ†åˆ©ç”¨ç°ä»£CPUçš„å¤šæ ¸ä¼˜åŠ¿ï¼š

```java
public class ParallelTrainer {
    private ExecutorService executorService;
    private int threadCount;
    
    public void parallelTrainBatch(List<DataBatch> batches) {
        // åˆ›å»ºçº¿ç¨‹æ± 
        executorService = Executors.newFixedThreadPool(threadCount);
        
        // å°†æ‰¹æ¬¡åˆ†é…ç»™ä¸åŒçº¿ç¨‹
        List<Future<TrainingResult>> futures = new ArrayList<>();
        for (DataBatch batch : batches) {
            Future<TrainingResult> future = executorService.submit(() -> {
                // æ¯ä¸ªçº¿ç¨‹ç‹¬ç«‹è®­ç»ƒä¸€ä¸ªæ‰¹æ¬¡
                return trainSingleBatch(batch);
            });
            futures.add(future);
        }
        
        // æ”¶é›†è®­ç»ƒç»“æœå¹¶èšåˆæ¢¯åº¦
        List<Map<String, NdArray>> gradients = new ArrayList<>();
        for (Future<TrainingResult> future : futures) {
            TrainingResult result = future.get();
            gradients.add(result.getGradients());
        }
        
        // æ¢¯åº¦èšåˆå’Œå‚æ•°æ›´æ–°
        Map<String, NdArray> aggregatedGrads = aggregateGradients(gradients);
        optimizer.step(aggregatedGrads);
    }
}
```

## ç¬¬äº”ç« ï¼šå¤§è¯­è¨€æ¨¡å‹çš„å®ç°â€”â€”ä»GPTåˆ°ç°ä»£æ¶æ„

### 5.1 GPTç³»åˆ—ï¼šTransformerçš„æ¼”è¿›ä¹‹è·¯

TinyAIå®Œæ•´å®ç°äº†GPT-1åˆ°GPT-3çš„æ¶æ„æ¼”è¿›ï¼Œè®©æˆ‘ä»¬èƒ½å¤Ÿæ¸…æ™°åœ°çœ‹åˆ°å¤§è¯­è¨€æ¨¡å‹çš„å‘å±•è„‰ç»œï¼š

**GPT-1ï¼šTransformerçš„åˆæ¬¡åº”ç”¨**
```java
public class GPT1Model extends Model {
    private TokenEmbedding tokenEmbedding;
    private PositionalEncoding posEncoding;
    private List<TransformerBlock> transformerBlocks;
    private LayerNormalizationLayer finalNorm;
    private LinearLayer outputProjection;
    
    @Override
    public Variable forward(Variable... inputs) {
        Variable tokens = inputs[0];
        
        // 1. TokenåµŒå…¥ + ä½ç½®ç¼–ç 
        Variable embedded = tokenEmbedding.forward(tokens);
        Variable positioned = posEncoding.forward(embedded);
        
        // 2. å¤šå±‚Transformerå—
        Variable hidden = positioned;
        for (TransformerBlock block : transformerBlocks) {
            hidden = block.blockForward(hidden);
        }
        
        // 3. æœ€ç»ˆå½’ä¸€åŒ–å’Œè¾“å‡ºæŠ•å½±
        hidden = finalNorm.layerForward(hidden);
        return outputProjection.layerForward(hidden);
    }
}
```

**GPT-2ï¼šæ›´å¤§çš„æ¨¡å‹ï¼Œæ›´å¼ºçš„èƒ½åŠ›**
```java
public class GPT2Model extends GPT1Model {
    // GPT-2ç›¸å¯¹äºGPT-1çš„ä¸»è¦æ”¹è¿›ï¼š
    // 1. æ›´å¤§çš„æ¨¡å‹å‚æ•°ï¼ˆ1.5Bï¼‰
    // 2. æ›´å¤šçš„æ³¨æ„åŠ›å¤´å’Œå±‚æ•°
    // 3. æ”¹è¿›çš„åˆå§‹åŒ–ç­–ç•¥
    
    public static GPT2Model createMediumModel() {
        GPT2Config config = GPT2Config.builder()
            .vocabSize(50257)
            .hiddenSize(1024)
            .numLayers(24)
            .numHeads(16)
            .maxPositionEmbeddings(1024)
            .build();
        
        return new GPT2Model(config);
    }
}
```

**GPT-3ï¼šç¨€ç–æ³¨æ„åŠ›çš„æ¢ç´¢**
```java
public class GPT3Model extends GPT2Model {
    @Override
    protected MultiHeadAttentionLayer createAttentionLayer(GPT3Config config) {
        // GPT-3å¼•å…¥ç¨€ç–æ³¨æ„åŠ›æœºåˆ¶
        return new SparseMultiHeadAttentionLayer(
            config.getHiddenSize(),
            config.getNumHeads(),
            config.getAttentionPatterns()  // ç¨€ç–æ³¨æ„åŠ›æ¨¡å¼
        );
    }
}
```

### 5.2 ç°ä»£æ¶æ„ï¼šQwen3çš„å…ˆè¿›è®¾è®¡

TinyAIè¿˜å®ç°äº†æ›´ç°ä»£çš„Qwen3æ¨¡å‹ï¼Œé›†æˆäº†æœ€æ–°çš„æŠ€æœ¯è¿›å±•ï¼š

```java
public class Qwen3Model extends Model {
    @Override
    public Variable forward(Variable... inputs) {
        Variable tokens = inputs[0];
        
        // 1. åµŒå…¥å±‚
        Variable embedded = tokenEmbedding.forward(tokens);
        
        // 2. å¤šä¸ªDecoderå—ï¼ˆé›†æˆäº†ç°ä»£æŠ€æœ¯ï¼‰
        Variable hidden = embedded;
        for (Qwen3DecoderBlock block : decoderBlocks) {
            hidden = block.blockForward(hidden);
        }
        
        // 3. RMSå½’ä¸€åŒ–ï¼ˆæ›¿ä»£LayerNormï¼‰
        hidden = rmsNorm.layerForward(hidden);
        
        return outputProjection.layerForward(hidden);
    }
}

public class Qwen3DecoderBlock extends Block {
    private Qwen3AttentionBlock attention;    // é›†æˆGQAå’ŒRoPE
    private Qwen3MLPBlock mlp;               // é›†æˆSwiGLUæ¿€æ´»
    private RMSNormLayer preAttnNorm;
    private RMSNormLayer preMlpNorm;
    
    @Override
    public Variable blockForward(Variable... inputs) {
        Variable input = inputs[0];
        
        // é¢„å½’ä¸€åŒ– + æ³¨æ„åŠ› + æ®‹å·®è¿æ¥
        Variable normed1 = preAttnNorm.layerForward(input);
        Variable attnOut = attention.blockForward(normed1);
        Variable residual1 = input.add(attnOut);
        
        // é¢„å½’ä¸€åŒ– + MLP + æ®‹å·®è¿æ¥
        Variable normed2 = preMlpNorm.layerForward(residual1);
        Variable mlpOut = mlp.blockForward(normed2);
        return residual1.add(mlpOut);
    }
}
```

**å…³é”®æŠ€æœ¯å®ç°ï¼š**

1. **RoPEä½ç½®ç¼–ç **ï¼š
```java
public class RotaryPositionalEmbeddingLayer extends Layer {
    @Override
    public Variable layerForward(Variable... inputs) {
        Variable x = inputs[0];
        int seqLen = x.getValue().getShape().get(1);
        int dim = x.getValue().getShape().get(2);
        
        // è®¡ç®—æ—‹è½¬è§’åº¦
        NdArray freqs = computeFrequencies(dim, seqLen);
        
        // åº”ç”¨æ—‹è½¬å˜æ¢
        return applyRotaryEmbedding(x, freqs);
    }
}
```

2. **åˆ†ç»„æŸ¥è¯¢æ³¨æ„åŠ›ï¼ˆGQAï¼‰**ï¼š
```java
public class GroupedQueryAttention extends Layer {
    private int numHeads;
    private int numKeyValueHeads;  // KVå¤´æ•°å°‘äºQå¤´æ•°
    
    @Override
    public Variable layerForward(Variable... inputs) {
        // Qã€Kã€VæŠ•å½±ï¼Œä½†Kå’ŒVå…±äº«å‚æ•°ç»„
        Variable q = queryProjection.layerForward(inputs[0]);
        Variable k = keyProjection.layerForward(inputs[0]);
        Variable v = valueProjection.layerForward(inputs[0]);
        
        // é‡å¤Kå’ŒVä»¥åŒ¹é…Qçš„å¤´æ•°
        k = repeatKVHeads(k);
        v = repeatKVHeads(v);
        
        return computeAttention(q, k, v);
    }
}
```

## ç¬¬å…­ç« ï¼šæ™ºèƒ½ä½“ç³»ç»Ÿâ€”â€”èµ‹äºˆAIæ€è€ƒçš„èƒ½åŠ›

### 6.1 æ™ºèƒ½ä½“çš„å±‚æ¬¡åŒ–è®¾è®¡

```mermaid
graph TB
    subgraph "æ™ºèƒ½ä½“èƒ½åŠ›é‡‘å­—å¡”"
        L1[ğŸ§  è‡ªæˆ‘è¿›åŒ–<br/>åæ€å­¦ä¹ ã€ç­–ç•¥ä¼˜åŒ–]
        L2[ğŸ¤ åä½œäº¤äº’<br/>å¤šæ™ºèƒ½ä½“ã€ä»»åŠ¡åˆ†å·¥]
        L3[ğŸ” çŸ¥è¯†æ£€ç´¢<br/>RAGç³»ç»Ÿã€è¯­ä¹‰æœç´¢]
        L4[ğŸ’­ æ¨ç†æ€è€ƒ<br/>è®¤çŸ¥æ¨¡å¼ã€é€»è¾‘æ¨å¯¼]
        L5[ğŸ‘ï¸ æ„ŸçŸ¥ç†è§£<br/>è¾“å…¥å¤„ç†ã€æ„å›¾è¯†åˆ«]
        L6[ğŸ› ï¸ åŸºç¡€èƒ½åŠ›<br/>è®°å¿†ç®¡ç†ã€å·¥å…·è°ƒç”¨]
        
        L6 --> L5
        L5 --> L4
        L4 --> L3
        L3 --> L2
        L2 --> L1
    end
```


TinyAIçš„æ™ºèƒ½ä½“ç³»ç»Ÿä»æœ€åŸºç¡€çš„Agentå¼€å§‹ï¼Œé€æ­¥å‘å±•åˆ°å…·å¤‡è‡ªæˆ‘è¿›åŒ–èƒ½åŠ›çš„é«˜çº§æ™ºèƒ½ä½“ï¼š

```java
// åŸºç¡€æ™ºèƒ½ä½“ï¼šå…·å¤‡åŸºæœ¬çš„æ„ŸçŸ¥å’Œè¡ŒåŠ¨èƒ½åŠ›
public abstract class BaseAgent {
    protected String name;
    protected String systemPrompt;
    protected Memory memory;
    protected ToolRegistry toolRegistry;
    
    public abstract AgentResponse processMessage(String message);
    
    protected Object performTask(AgentTask task) throws Exception {
        // ä»»åŠ¡æ‰§è¡Œçš„åŸºæœ¬æµç¨‹
        return null;
    }
}

// é«˜çº§æ™ºèƒ½ä½“ï¼šå…·å¤‡å­¦ä¹ å’Œæ¨ç†èƒ½åŠ›
public class AdvancedAgent extends BaseAgent {
    private KnowledgeBase knowledgeBase;
    private ReasoningEngine reasoningEngine;
    
    @Override
    public AgentResponse processMessage(String message) {
        // 1. ç†è§£ç”¨æˆ·æ„å›¾
        Intent intent = intentRecognition.analyze(message);
        
        // 2. æ£€ç´¢ç›¸å…³çŸ¥è¯†
        List<Knowledge> relevantKnowledge = knowledgeBase.retrieve(intent);
        
        // 3. æ¨ç†å’Œç”Ÿæˆå›ç­”
        String response = reasoningEngine.generateResponse(intent, relevantKnowledge);
        
        // 4. æ›´æ–°è®°å¿†
        memory.store(new Conversation(message, response));
        
        return new AgentResponse(response);
    }
}
```

### 6.2 è‡ªè¿›åŒ–æ™ºèƒ½ä½“ï¼šå…·å¤‡å­¦ä¹ èƒ½åŠ›çš„AI

```mermaid
graph TD
    subgraph "è‡ªè¿›åŒ–å¾ªç¯"
        A[ğŸ¯ æ‰§è¡Œä»»åŠ¡] --> B[ğŸ“Š æ”¶é›†ç»éªŒ]
        B --> C[ğŸ§  åˆ†æåæ€]
        C --> D[âš¡ ç­–ç•¥ä¼˜åŒ–]
        D --> E[ğŸ“ˆ èƒ½åŠ›æå‡]
        E --> A
    end
    
    subgraph "å­¦ä¹ æœºåˆ¶"
        F[ç»éªŒç¼“å†²åŒº<br/>Experience Buffer]
        G[æ€§èƒ½åˆ†æå™¨<br/>Performance Analyzer]
        H[ç­–ç•¥ä¼˜åŒ–å™¨<br/>Strategy Optimizer]
        I[çŸ¥è¯†å›¾è°±<br/>Knowledge Graph]
    end
    
    B --> F
    C --> G
    D --> H
    E --> I
```

è‡ªè¿›åŒ–æ™ºèƒ½ä½“æ˜¯TinyAIçš„ä¸€ä¸ªé‡è¦åˆ›æ–°ï¼Œå®ƒèƒ½å¤Ÿä»ç»éªŒä¸­å­¦ä¹ å¹¶ä¼˜åŒ–è‡ªå·±çš„è¡Œä¸ºï¼š

```java
public class SelfEvolvingAgent extends AdvancedAgent {
    private ExperienceBuffer experienceBuffer;
    private StrategyOptimizer strategyOptimizer;
    private KnowledgeGraphBuilder knowledgeGraphBuilder;
    
    @Override
    public TaskResult processTask(String taskName, TaskContext context) {
        // 1. è®°å½•ä»»åŠ¡å¼€å§‹çŠ¶æ€
        TaskSnapshot snapshot = captureTaskSnapshot(taskName, context);
        
        // 2. æ‰§è¡Œä»»åŠ¡
        TaskResult result = super.processTask(taskName, context);
        
        // 3. è®°å½•ç»éªŒ
        Experience experience = new Experience(snapshot, result);
        experienceBuffer.add(experience);
        
        // 4. è§¦å‘å­¦ä¹ ï¼ˆå¦‚æœéœ€è¦ï¼‰
        if (shouldTriggerLearning()) {
            selfEvolve();
        }
        
        return result;
    }
    
    public void selfEvolve() {
        // 1. ç»éªŒåˆ†æ
        List<Experience> recentExperiences = experienceBuffer.getRecentExperiences();
        PerformanceAnalysis analysis = analyzePerformance(recentExperiences);
        
        // 2. ç­–ç•¥ä¼˜åŒ–
        if (analysis.hasImprovementOpportunity()) {
            Strategy newStrategy = strategyOptimizer.optimize(analysis);
            updateStrategy(newStrategy);
        }
        
        // 3. çŸ¥è¯†å›¾è°±æ›´æ–°
        List<KnowledgeNode> newNodes = extractKnowledgeFromExperiences(recentExperiences);
        knowledgeGraphBuilder.updateGraph(newNodes);
        
        // 4. èƒ½åŠ›æå‡
        enhanceCapabilities(analysis);
    }
}
```

### 6.3 å¤šæ™ºèƒ½ä½“åä½œï¼šé›†ä½“æ™ºæ…§çš„ä½“ç°

TinyAIæ”¯æŒå¤šä¸ªæ™ºèƒ½ä½“ä¹‹é—´çš„åä½œï¼Œå®ç°å¤æ‚ä»»åŠ¡çš„åˆ†å·¥åˆä½œï¼š

```mermaid
graph TB
    subgraph "åä½œåœºæ™¯ç¤ºä¾‹ï¼šæŠ€æœ¯æ–‡æ¡£ç”Ÿæˆ"
        Task[ğŸ“ æ–‡æ¡£ç”Ÿæˆä»»åŠ¡] --> Coordinator[ğŸ¯ ä»»åŠ¡åè°ƒå™¨]
        
        Coordinator --> Agent1[ğŸ“š ç ”ç©¶ä¸“å®¶<br/>æ”¶é›†æŠ€æœ¯èµ„æ–™]
        Coordinator --> Agent2[âœï¸ å†™ä½œä¸“å®¶<br/>å†…å®¹åˆ›ä½œç¼–è¾‘] 
        Coordinator --> Agent3[ğŸ¨ è®¾è®¡ä¸“å®¶<br/>å›¾è¡¨å¯è§†åŒ–]
        Coordinator --> Agent4[ğŸ” å®¡æ ¸ä¸“å®¶<br/>è´¨é‡æŠŠæ§]
        
        Agent1 --> Aggregator[ğŸ”„ ç»“æœèšåˆå™¨]
        Agent2 --> Aggregator
        Agent3 --> Aggregator
        Agent4 --> Aggregator
        
        Aggregator --> Result[ğŸ“„ æœ€ç»ˆæ–‡æ¡£]
    end
```

### 6.4 RAGç³»ç»Ÿï¼šçŸ¥è¯†æ£€ç´¢å¢å¼ºç”Ÿæˆ

TinyAIå®ç°äº†å®Œæ•´çš„RAGï¼ˆRetrieval-Augmented Generationï¼‰ç³»ç»Ÿï¼š

```mermaid
graph LR
    subgraph "çŸ¥è¯†å‡†å¤‡é˜¶æ®µ"
        A[ğŸ“„ åŸå§‹æ–‡æ¡£] --> B[âœ‚ï¸ æ–‡æ¡£åˆ‡ç‰‡]
        B --> C[ğŸ”¢ å‘é‡åŒ–ç¼–ç ]
        C --> D[ğŸ—ƒï¸ å‘é‡æ•°æ®åº“]
    end
    
    subgraph "é—®ç­”ç”Ÿæˆé˜¶æ®µ"
        E[â“ ç”¨æˆ·é—®é¢˜] --> F[ğŸ” è¯­ä¹‰æ£€ç´¢]
        F --> D
        D --> G[ğŸ“‹ ç›¸å…³ä¸Šä¸‹æ–‡]
        G --> H[ğŸ¤– å¤§æ¨¡å‹ç”Ÿæˆ]
        H --> I[ğŸ’¬ æ™ºèƒ½å›ç­”]
    end
```

```java
public class RAGSystem {
    private VectorDatabase vectorDB;
    private TextEncoder textEncoder;
    private DocumentProcessor documentProcessor;
    
    public String generateAnswer(String question, List<Document> documents) {
        // 1. æ–‡æ¡£é¢„å¤„ç†å’Œå‘é‡åŒ–
        for (Document doc : documents) {
            List<TextChunk> chunks = documentProcessor.chunkDocument(doc);
            for (TextChunk chunk : chunks) {
                NdArray embedding = textEncoder.encode(chunk.getText());
                vectorDB.store(chunk.getId(), embedding, chunk);
            }
        }
        
        // 2. é—®é¢˜å‘é‡åŒ–
        NdArray questionEmbedding = textEncoder.encode(question);
        
        // 3. ç›¸ä¼¼åº¦æ£€ç´¢
        List<RetrievalResult> relevantChunks = vectorDB.similaritySearch(
            questionEmbedding, topK: 5);
        
        // 4. ä¸Šä¸‹æ–‡æ„å»º
        String context = buildContext(relevantChunks);
        
        // 5. ç”Ÿæˆå›ç­”
        String prompt = String.format(
            "åŸºäºä»¥ä¸‹ä¸Šä¸‹æ–‡å›ç­”é—®é¢˜ï¼š\nä¸Šä¸‹æ–‡ï¼š%s\né—®é¢˜ï¼š%s\nå›ç­”ï¼š", 
            context, question);
        
        return textGenerator.generate(prompt);
    }
}
```

## ç¬¬ä¸ƒç« ï¼šè®¾è®¡ç†å¿µä¸æŠ€æœ¯å“²å­¦

### 7.1 é¢å‘å¯¹è±¡è®¾è®¡çš„ç²¾é«“

TinyAIçš„è®¾è®¡å……åˆ†ä½“ç°äº†é¢å‘å¯¹è±¡ç¼–ç¨‹çš„ç²¾é«“ï¼š

**1. å•ä¸€èŒè´£åŸåˆ™**
```java
// æ¯ä¸ªç±»éƒ½æœ‰æ˜ç¡®çš„å•ä¸€èŒè´£
public class LinearLayer extends Layer {        // åªè´Ÿè´£çº¿æ€§å˜æ¢
public class ReluLayer extends Layer {          // åªè´Ÿè´£ReLUæ¿€æ´»
public class SoftmaxLayer extends Layer {       // åªè´Ÿè´£Softmaxè®¡ç®—
```

**2. å¼€é—­åŸåˆ™**
```java
// å¯¹æ‰©å±•å¼€æ”¾ï¼Œå¯¹ä¿®æ”¹å°é—­
public abstract class Layer {
    // åŸºç¡€åŠŸèƒ½ç¨³å®šä¸å˜
    public final Variable forward(Variable... inputs) {
        return layerForward(inputs);  // å§”æ‰˜ç»™å­ç±»å®ç°
    }
    
    // æ‰©å±•ç‚¹ï¼šå­ç±»å¯ä»¥å®ç°è‡ªå·±çš„è®¡ç®—é€»è¾‘
    protected abstract Variable layerForward(Variable... inputs);
}
```

**3. ä¾èµ–å€’ç½®åŸåˆ™**
```java
// é«˜å±‚æ¨¡å—ä¸ä¾èµ–ä½å±‚æ¨¡å—ï¼Œéƒ½ä¾èµ–æŠ½è±¡
public class Trainer {
    private LossFunction lossFunction;      // ä¾èµ–æŠ½è±¡æ¥å£
    private Optimizer optimizer;            // ä¾èµ–æŠ½è±¡æ¥å£
    private Evaluator evaluator;            // ä¾èµ–æŠ½è±¡æ¥å£
    
    // é€šè¿‡ä¾èµ–æ³¨å…¥è·å¾—å…·ä½“å®ç°
    public void init(DataSet dataSet, Model model, 
                    LossFunction loss, Optimizer opt) {
        this.lossFunction = loss;
        this.optimizer = opt;
    }
}
```

### 7.2 è®¾è®¡æ¨¡å¼çš„å·§å¦™è¿ç”¨

**1. ç»„åˆæ¨¡å¼ï¼šæ„å»ºå¤æ‚ç½‘ç»œ**
```java
public class SequentialBlock extends Block {
    private List<Layer> layers = new ArrayList<>();
    
    public SequentialBlock addLayer(Layer layer) {
        layers.add(layer);
        return this;  // æ”¯æŒé“¾å¼è°ƒç”¨
    }
    
    @Override
    public Variable blockForward(Variable... inputs) {
        Variable output = inputs[0];
        for (Layer layer : layers) {
            output = layer.layerForward(output);  // é€å±‚å‰å‘ä¼ æ’­
        }
        return output;
    }
}
```

**2. ç­–ç•¥æ¨¡å¼ï¼šçµæ´»çš„ç®—æ³•é€‰æ‹©**
```java
// ä¼˜åŒ–å™¨ç­–ç•¥
public interface Optimizer {
    void step(Map<String, Variable> parameters);
}

public class SgdOptimizer implements Optimizer {
    public void step(Map<String, Variable> parameters) {
        // SGDä¼˜åŒ–ç­–ç•¥
    }
}

public class AdamOptimizer implements Optimizer {
    public void step(Map<String, Variable> parameters) {
        // Adamä¼˜åŒ–ç­–ç•¥
    }
}
```

**3. è§‚å¯Ÿè€…æ¨¡å¼ï¼šè®­ç»ƒè¿‡ç¨‹ç›‘æ§**
```java
public class TrainingMonitor {
    private List<TrainingListener> listeners = new ArrayList<>();
    
    public void addListener(TrainingListener listener) {
        listeners.add(listener);
    }
    
    public void notifyEpochComplete(int epoch, float loss, float accuracy) {
        for (TrainingListener listener : listeners) {
            listener.onEpochComplete(epoch, loss, accuracy);
        }
    }
}
```

### 7.3 å†…å­˜ç®¡ç†ä¸æ€§èƒ½ä¼˜åŒ–

**1. æ™ºèƒ½çš„å†…å­˜ç®¡ç†**
```java
public class NdArrayCpu implements NdArray {
    private float[] data;
    private Shape shape;
    private boolean isView = false;  // æ ‡è®°æ˜¯å¦ä¸ºè§†å›¾ï¼ˆå…±äº«æ•°æ®ï¼‰
    
    // é¿å…ä¸å¿…è¦çš„æ•°æ®æ‹·è´
    public NdArray reshape(Shape newShape) {
        if (newShape.size() != shape.size()) {
            throw new IllegalArgumentException("Shape size mismatch");
        }
        
        NdArrayCpu result = new NdArrayCpu();
        result.data = this.data;      // å…±äº«åº•å±‚æ•°æ®
        result.shape = newShape;
        result.isView = true;         // æ ‡è®°ä¸ºè§†å›¾
        return result;
    }
}
```

**2. è®¡ç®—å›¾çš„æ™ºèƒ½å‰ªæ**
```java
public class Variable {
    public void unChainBackward() {
        // åˆ‡æ–­è®¡ç®—å›¾ï¼Œé‡Šæ”¾ä¸éœ€è¦çš„å¼•ç”¨
        Function creatorFunc = creator;
        if (creatorFunc != null) {
            Variable[] xs = creatorFunc.getInputs();
            unChain();  // æ¸…é™¤å½“å‰èŠ‚ç‚¹çš„creatorå¼•ç”¨
            for (Variable x : xs) {
                x.unChainBackward();  // é€’å½’åˆ‡æ–­
            }
        }
    }
}
```

### 7.4 é”™è¯¯å¤„ç†ä¸è°ƒè¯•å‹å¥½

**1. ä¸°å¯Œçš„é”™è¯¯ä¿¡æ¯**
```java
public NdArray dot(NdArray other) {
    if (!isMatrix() || !other.isMatrix()) {
        throw new IllegalArgumentException(
            String.format("Matrix multiplication requires 2D arrays. " +
                         "Got shapes: %s and %s", 
                         this.getShape(), other.getShape()));
    }
    
    if (this.getShape().get(1) != other.getShape().get(0)) {
        throw new IllegalArgumentException(
            String.format("Matrix dimensions mismatch for multiplication: " +
                         "(%d x %d) * (%d x %d)", 
                         this.getShape().get(0), this.getShape().get(1),
                         other.getShape().get(0), other.getShape().get(1)));
    }
    
    return dotImpl(other);
}
```

**2. è°ƒè¯•ä¿¡æ¯çš„ä¿ç•™**
```java
public class Variable {
    private String name;  // å˜é‡åç§°ï¼Œä¾¿äºè°ƒè¯•
    
    @Override
    public String toString() {
        return String.format("Variable(name='%s', shape=%s, requireGrad=%s)", 
                           name, value.getShape(), requireGrad);
    }
}
```

## ç¬¬å…«ç« ï¼šå®é™…åº”ç”¨æ¡ˆä¾‹

### 8.1 MNISTæ‰‹å†™æ•°å­—è¯†åˆ«

**é—®é¢˜åœºæ™¯**ï¼šç»å…¸çš„è®¡ç®—æœºè§†è§‰å…¥é—¨ä»»åŠ¡

```mermaid
graph LR
    A[ğŸ“¸ æ‰‹å†™æ•°å­—å›¾åƒ<br/>28x28åƒç´ ] --> B[ğŸ”„ æ•°æ®é¢„å¤„ç†<br/>å½’ä¸€åŒ–/å±•å¹³]
    B --> C[ğŸ§  MLPç½‘ç»œ<br/>784â†’128â†’64â†’10]
    C --> D[ğŸ“Š Softmaxè¾“å‡º<br/>10ä¸ªç±»åˆ«æ¦‚ç‡]
    D --> E[ğŸ¯ é¢„æµ‹ç»“æœ<br/>0-9æ•°å­—]
```

**è®­ç»ƒæ•ˆæœå¯è§†åŒ–**ï¼š
```
ğŸ“ˆ è®­ç»ƒè¿›åº¦å±•ç¤º
Epoch 1/50:  Loss=2.156, Accuracy=23.4% â–ˆâ–ˆâ–ˆâ–ˆâ–’â–’â–’â–’â–’â–’
Epoch 10/50: Loss=0.845, Accuracy=75.6% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’â–’
Epoch 25/50: Loss=0.234, Accuracy=89.3% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–’
Epoch 50/50: Loss=0.089, Accuracy=97.3% â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ

ğŸ¯ æœ€ç»ˆæµ‹è¯•å‡†ç¡®ç‡: 97.3%
```

### 8.2 æ™ºèƒ½å®¢æœç³»ç»Ÿ

```java
public class IntelligentCustomerService {
    public static void main(String[] args) {
        // 1. åˆ›å»ºRAGç³»ç»Ÿ
        RAGSystem ragSystem = new RAGSystem();
        
        // 2. åŠ è½½ä¼ä¸šçŸ¥è¯†åº“
        List<Document> knowledgeBase = Arrays.asList(
            new Document("äº§å“è¯´æ˜ä¹¦", loadProductDocs()),
            new Document("å¸¸è§é—®é¢˜", loadFAQs()),
            new Document("æœåŠ¡æµç¨‹", loadServiceProcesses())
        );
        
        // 3. åˆ›å»ºæ™ºèƒ½å®¢æœAgent
        AdvancedAgent customerServiceAgent = new AdvancedAgent(
            "æ™ºèƒ½å®¢æœå°åŠ©æ‰‹", 
            "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å®¢æœåŠ©æ‰‹ï¼Œèƒ½å¤ŸåŸºäºä¼ä¸šçŸ¥è¯†åº“å›ç­”ç”¨æˆ·é—®é¢˜"
        );
        
        // 4. é›†æˆRAGèƒ½åŠ›
        customerServiceAgent.addTool("knowledge_search", 
            (query) -> ragSystem.generateAnswer(query, knowledgeBase));
        
        // 5. å¤„ç†å®¢æˆ·å’¨è¯¢
        Scanner scanner = new Scanner(System.in);
        System.out.println("æ™ºèƒ½å®¢æœç³»ç»Ÿå¯åŠ¨ï¼Œè¯·è¾“å…¥æ‚¨çš„é—®é¢˜ï¼š");
        
        while (true) {
            String userInput = scanner.nextLine();
            if ("é€€å‡º".equals(userInput)) break;
            
            AgentResponse response = customerServiceAgent.processMessage(userInput);
            System.out.println("å®¢æœåŠ©æ‰‹ï¼š" + response.getMessage());
        }
    }
}
```

### 8.3 è‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ

```mermaid
graph LR
    subgraph "æ•°æ®è¾“å…¥"
        D1[ğŸ“ˆ è‚¡ä»·å†å²]
        D2[ğŸ“Š æŠ€æœ¯æŒ‡æ ‡]
        D3[ğŸ“° æ–°é—»æƒ…æ„Ÿ]
        D4[ğŸ’¹ å¸‚åœºæ•°æ®]
    end
    
    subgraph "æ¨¡å‹å¤„ç†"
        M1[ğŸ”„ LSTMç½‘ç»œ<br/>æ—¶åºå»ºæ¨¡]
        M2[ğŸ§  æ³¨æ„åŠ›æœºåˆ¶<br/>é‡è¦ä¿¡æ¯èšç„¦]
        M3[ğŸ¯ å…¨è¿æ¥å±‚<br/>æœ€ç»ˆé¢„æµ‹]
    end
    
    subgraph "è¾“å‡ºç»“æœ"
        O1[ğŸ“ˆ ä»·æ ¼é¢„æµ‹]
        O2[ğŸ“Š ç½®ä¿¡åŒºé—´]
        O3[âš ï¸ é£é™©è¯„ä¼°]
    end
    
    D1 --> M1
    D2 --> M1
    D3 --> M2
    D4 --> M2
    
    M1 --> M3
    M2 --> M3
    
    M3 --> O1
    M3 --> O2
    M3 --> O3
```


```java
public class StockPredictionSystem {
    public static void main(String[] args) {
        // 1. æ„å»ºLSTMç½‘ç»œ
        SequentialBlock lstm = new SequentialBlock("stock_predictor");
        lstm.addLayer(new LstmLayer("lstm1", 10, 50))      // è¾“å…¥10ä¸ªç‰¹å¾ï¼Œéšè—50ç»´
            .addLayer(new DropoutLayer("dropout1", 0.2f))
            .addLayer(new LstmLayer("lstm2", 50, 25))       // ç¬¬äºŒå±‚LSTM
            .addLayer(new DropoutLayer("dropout2", 0.2f))
            .addLayer(new LinearLayer("output", 25, 1))     // è¾“å‡ºå±‚é¢„æµ‹ä»·æ ¼
            .addLayer(new LinearLayer("final", 1, 1));      // æœ€ç»ˆè¾“å‡º
        
        Model model = new Model("stock_predictor", lstm);
        
        // 2. å‡†å¤‡æ—¶é—´åºåˆ—æ•°æ®
        TimeSeriesDataSet stockData = new TimeSeriesDataSet(
            loadStockData("AAPL", "2020-01-01", "2023-12-31"),
            sequenceLength: 30,  // ä½¿ç”¨30å¤©çš„å†å²æ•°æ®é¢„æµ‹ä¸‹ä¸€å¤©
            features: Arrays.asList("open", "high", "low", "close", "volume", 
                                   "ma5", "ma20", "rsi", "macd", "volume_ma")
        );
        
        // 3. è®­ç»ƒæ¨¡å‹
        Trainer trainer = new Trainer(100, new TrainingMonitor(), 
                                    new MSEEvaluator());
        trainer.init(stockData, model, 
                    new MeanSquaredErrorLoss(), 
                    new AdamOptimizer(0.001f));
        trainer.train(true);
        
        // 4. é¢„æµ‹æœªæ¥ä»·æ ¼
        Variable prediction = model.forward(stockData.getLastSequence());
        float predictedPrice = prediction.getValue().getNumber().floatValue();
        
        System.out.printf("é¢„æµ‹æ˜æ—¥è‚¡ä»·: $%.2f\n", predictedPrice);
    }
}
```

## ç¬¬ä¹ç« ï¼šæ€§èƒ½ä¼˜åŒ–ä¸æœ€ä½³å®è·µ

### 9.1 æ€§èƒ½ä¼˜åŒ–ç­–ç•¥

**1. å†…å­˜æ± æŠ€æœ¯**
```java
public class NdArrayPool {
    private static final Map<Shape, Queue<NdArrayCpu>> pool = new ConcurrentHashMap<>();
    
    public static NdArrayCpu acquire(Shape shape) {
        Queue<NdArrayCpu> queue = pool.computeIfAbsent(shape, 
            k -> new ConcurrentLinkedQueue<>());
        
        NdArrayCpu array = queue.poll();
        if (array == null) {
            array = new NdArrayCpu(shape);
        }
        return array;
    }
    
    public static void release(NdArrayCpu array) {
        // æ¸…é›¶æ•°æ®å¹¶è¿”å›æ± ä¸­
        Arrays.fill(array.getData(), 0.0f);
        Queue<NdArrayCpu> queue = pool.get(array.getShape());
        if (queue != null) {
            queue.offer(array);
        }
    }
}
```

**2. æ‰¹é‡è®¡ç®—ä¼˜åŒ–**
```java
public class BatchProcessor {
    public static NdArray batchMatMul(List<NdArray> matrices1, 
                                     List<NdArray> matrices2) {
        // å°†å¤šä¸ªçŸ©é˜µä¹˜æ³•åˆå¹¶ä¸ºä¸€æ¬¡æ‰¹é‡æ“ä½œ
        NdArray batch1 = NdArray.stack(matrices1, axis: 0);
        NdArray batch2 = NdArray.stack(matrices2, axis: 0);
        
        return batch1.batchDot(batch2);  // æ‰¹é‡çŸ©é˜µä¹˜æ³•ï¼Œå……åˆ†åˆ©ç”¨å¹¶è¡Œæ€§
    }
}
```

### 9.2 æœ€ä½³å®è·µæŒ‡å—

**1. æ¨¡å‹è®¾è®¡æœ€ä½³å®è·µ**
```java
// âœ… å¥½çš„åšæ³•ï¼šå±‚æ¬¡æ¸…æ™°ï¼Œæ˜“äºç†è§£å’Œè°ƒè¯•
public class GoodModelDesign {
    public Model createModel() {
        // ç‰¹å¾æå–å™¨
        Block featureExtractor = new SequentialBlock("feature_extractor")
            .addLayer(new LinearLayer("fe1", 784, 512))
            .addLayer(new BatchNormalizationLayer("bn1", 512))
            .addLayer(new ReluLayer("relu1"))
            .addLayer(new DropoutLayer("dropout1", 0.3f));
        
        // åˆ†ç±»å™¨
        Block classifier = new SequentialBlock("classifier")
            .addLayer(new LinearLayer("cls1", 512, 256))
            .addLayer(new ReluLayer("relu2"))
            .addLayer(new LinearLayer("cls2", 256, 10))
            .addLayer(new SoftmaxLayer("softmax"));
        
        // ç»„åˆæ¨¡å‹
        SequentialBlock fullModel = new SequentialBlock("full_model")
            .addBlock(featureExtractor)
            .addBlock(classifier);
        
        return new Model("mnist_advanced", fullModel);
    }
}

// âŒ ä¸å¥½çš„åšæ³•ï¼šæ‰€æœ‰å±‚æ··åœ¨ä¸€èµ·ï¼Œéš¾ä»¥ç†è§£å’Œä¿®æ”¹
public class BadModelDesign {
    public Model createModel() {
        SequentialBlock model = new SequentialBlock("model");
        model.addLayer(new LinearLayer("l1", 784, 512))
             .addLayer(new BatchNormalizationLayer("b1", 512))
             .addLayer(new ReluLayer("rx"))
             .addLayer(new DropoutLayer("d1", 0.3f))
             .addLayer(new LinearLayer("l2", 512, 256))
             .addLayer(new ReluLayer("r2"))
             .addLayer(new LinearLayer("l3", 256, 10))
             .addLayer(new SoftmaxLayer("s1"));
        
        return new Model("mnist_bad", model);
    }
}
```

**2. è®­ç»ƒè¿‡ç¨‹æœ€ä½³å®è·µ**
```java
public class TrainingBestPractices {
    public void trainModel() {
        // âœ… ä½¿ç”¨å­¦ä¹ ç‡è°ƒåº¦
        LearningRateScheduler scheduler = new CosineAnnealingScheduler(
            initialLR: 0.01f, minLR: 0.001f, maxEpochs: 100);
        
        // âœ… ä½¿ç”¨æ—©åœæœºåˆ¶
        EarlyStopping earlyStopping = new EarlyStopping(
            patience: 10, minDelta: 0.001f);
        
        // âœ… ä½¿ç”¨æ£€æŸ¥ç‚¹ä¿å­˜
        ModelCheckpoint checkpoint = new ModelCheckpoint(
            "best_model.json", saveOnlyBest: true);
        
        Trainer trainer = new Trainer(100, new TrainingMonitor(), 
                                    new AccuracyEvaluator());
        trainer.addCallback(scheduler)
               .addCallback(earlyStopping)
               .addCallback(checkpoint);
        
        trainer.train(true);
    }
}
```

## ç¬¬åç« ï¼šæœªæ¥å±•æœ›ä¸ç¤¾åŒºå»ºè®¾

### 10.1 æŠ€æœ¯å‘å±•è·¯çº¿å›¾

TinyAIçš„æœªæ¥å‘å±•å°†å›´ç»•ä»¥ä¸‹å‡ ä¸ªæ–¹å‘ï¼š

**1. ç¡¬ä»¶åŠ é€Ÿæ”¯æŒ**
```java
// è®¡åˆ’æ”¯æŒGPUåŠ é€Ÿ
public interface NdArray {
    NdArray toGPU();         // æ•°æ®è¿ç§»åˆ°GPU
    NdArray toCPU();         // æ•°æ®è¿ç§»å›CPU
    DeviceType getDevice();  // è·å–å½“å‰è®¾å¤‡ç±»å‹
}

// æ”¯æŒåˆ†å¸ƒå¼è®­ç»ƒ
public class DistributedTrainer extends Trainer {
    private List<TrainingNode> nodes;
    
    public void distributedTrain() {
        // AllReduceæ¢¯åº¦èšåˆ
        // å‚æ•°åŒæ­¥
        // è´Ÿè½½å‡è¡¡
    }
}
```

**2. æ¨¡å‹é‡åŒ–ä¸å‹ç¼©**
```java
public class ModelQuantization {
    public Model quantizeToInt8(Model model) {
        // å°†Float32æ¨¡å‹é‡åŒ–ä¸ºInt8
        // å‡å°‘æ¨¡å‹å¤§å°å’Œæ¨ç†æ—¶é—´
    }
    
    public Model pruneModel(Model model, float sparsity) {
        // æ¨¡å‹å‰ªæï¼Œç§»é™¤ä¸é‡è¦çš„è¿æ¥
        // ä¿æŒç²¾åº¦çš„åŒæ—¶å‡å°‘è®¡ç®—é‡
    }
}
```

**3. æ›´ä¸°å¯Œçš„æ¨¡å‹ç”Ÿæ€**
```java
// è®¡ç®—æœºè§†è§‰æ¨¡å‹
public class VisionModels {
    public static Model createResNet50() { /* ... */ }
    public static Model createViT() { /* ... */ }
    public static Model createYOLOv8() { /* ... */ }
}

// è‡ªç„¶è¯­è¨€å¤„ç†æ¨¡å‹
public class NLPModels {
    public static Model createBERT() { /* ... */ }
    public static Model createT5() { /* ... */ }
    public static Model createLLaMA() { /* ... */ }
}
```

### 10.2 ç¤¾åŒºç”Ÿæ€å»ºè®¾

**1. å¼€å‘è€…å‹å¥½çš„å·¥å…·é“¾**
```bash
# TinyAI CLIå·¥å…·
tinyai create-project my-ai-app --template=chatbot
tinyai train --config=training.yaml --data=dataset/
tinyai deploy --model=best_model.json --endpoint=/api/predict
tinyai benchmark --model=my_model.json --dataset=test_data/
```

**2. ä¸°å¯Œçš„ç¤ºä¾‹å’Œæ•™ç¨‹**
- ä»é›¶å¼€å§‹çš„æ·±åº¦å­¦ä¹ è¯¾ç¨‹
- å®æˆ˜é¡¹ç›®æ¡ˆä¾‹é›†åˆ
- æœ€ä½³å®è·µæŒ‡å—
- æ€§èƒ½ä¼˜åŒ–æŠ€å·§

**3. æ’ä»¶åŒ–æ¶æ„**
```java
// æ”¯æŒç¬¬ä¸‰æ–¹æ’ä»¶
public interface TinyAIPlugin {
    String getName();
    String getVersion();
    void initialize(TinyAIContext context);
    void shutdown();
}

// æ’ä»¶ç®¡ç†å™¨
public class PluginManager {
    public void loadPlugin(String pluginPath) { /* ... */ }
    public void unloadPlugin(String pluginName) { /* ... */ }
    public List<TinyAIPlugin> getLoadedPlugins() { /* ... */ }
}
```

### 10.3 æ•™è‚²ä¸äººæ‰åŸ¹å…»

TinyAIä¸ä»…æ˜¯ä¸€ä¸ªæŠ€æœ¯æ¡†æ¶ï¼Œæ›´æ˜¯ä¸€ä¸ªæ•™è‚²å¹³å°ï¼š

**1. äº¤äº’å¼å­¦ä¹ ç¯å¢ƒ**
```java
public class InteractiveLearning {
    public void demonstrateBackpropagation() {
        // å¯è§†åŒ–åå‘ä¼ æ’­è¿‡ç¨‹
        Variable x = new Variable(NdArray.of(2.0f), "è¾“å…¥x");
        Variable w = new Variable(NdArray.of(3.0f), "æƒé‡w");
        Variable y = x.mul(w).add(x.squ());  // y = w*x + xÂ²
        
        // æ˜¾ç¤ºè®¡ç®—å›¾
        ComputationGraphVisualizer.display(y);
        
        // é€æ­¥å±•ç¤ºåå‘ä¼ æ’­
        y.backward();
        StepByStepVisualizer.showBackpropagation(y);
    }
}
```

**2. æ¸è¿›å¼å­¦ä¹ è·¯å¾„**
```
Level 1: åŸºç¡€æ¦‚å¿µ â†’ å¤šç»´æ•°ç»„ã€åŸºæœ¬è¿ç®—
Level 2: è‡ªåŠ¨å¾®åˆ† â†’ è®¡ç®—å›¾ã€æ¢¯åº¦è®¡ç®—
Level 3: ç¥ç»ç½‘ç»œ â†’ å±‚ã€å—ã€ç½‘ç»œæ„å»º
Level 4: è®­ç»ƒè¿‡ç¨‹ â†’ ä¼˜åŒ–å™¨ã€æŸå¤±å‡½æ•°
Level 5: é«˜çº§æ¨¡å‹ â†’ Transformerã€LSTM
Level 6: æ™ºèƒ½ä½“ç³»ç»Ÿ â†’ RAGã€å¤šæ™ºèƒ½ä½“åä½œ
```

## ç»“è¯­ï¼šJava AIç”Ÿæ€çš„æ–°èµ·ç‚¹

TinyAIé¡¹ç›®ä»£è¡¨äº†Javaåœ¨AIé¢†åŸŸçš„ä¸€æ¬¡é‡è¦æ¢ç´¢ã€‚å®ƒä¸ä»…è¯æ˜äº†Javaåœ¨AIå¼€å‘ä¸­çš„å¯è¡Œæ€§ï¼Œæ›´å±•ç¤ºäº†é¢å‘å¯¹è±¡è®¾è®¡åœ¨å¤æ‚ç³»ç»Ÿä¸­çš„ä¼˜é›…å’ŒåŠ›é‡ã€‚

**TinyAIçš„ä»·å€¼åœ¨äºï¼š**

1. **æŠ€æœ¯ä»·å€¼**ï¼šå®Œæ•´çš„AIæ¡†æ¶å®ç°ï¼Œä»åº•å±‚æ•°å€¼è®¡ç®—åˆ°é«˜å±‚æ™ºèƒ½ä½“ç³»ç»Ÿ
2. **æ•™è‚²ä»·å€¼**ï¼šæ¸…æ™°çš„ä»£ç ç»“æ„å’Œè¯¦å°½çš„æ–‡æ¡£ï¼Œæ˜¯å­¦ä¹ AIçš„æœ€ä½³æ•™æ
3. **ç”Ÿæ€ä»·å€¼**ï¼šä¸ºJavaå¼€å‘è€…æä¾›äº†åŸç”Ÿçš„AIè§£å†³æ–¹æ¡ˆï¼Œä¿ƒè¿›æŠ€æœ¯æ ˆç»Ÿä¸€
4. **åˆ›æ–°ä»·å€¼**ï¼šåœ¨æ™ºèƒ½ä½“ç³»ç»Ÿã€è‡ªåŠ¨å¾®åˆ†ç­‰é¢†åŸŸæœ‰ç‹¬ç‰¹çš„è®¾è®¡å’Œå®ç°

**æœªæ¥çš„æ„¿æ™¯ï¼š**

æˆ‘ä»¬å¸Œæœ›TinyAIèƒ½å¤Ÿæˆä¸ºï¼š
- Java AIå¼€å‘çš„é¦–é€‰æ¡†æ¶
- AIæ•™è‚²çš„æ ‡å‡†æ•™æ
- å¼€æºç¤¾åŒºåä½œçš„å…¸èŒƒ
- äº§ä¸šåº”ç”¨çš„å¯é åŸºç¡€

æ­£å¦‚TinyAIçš„åå­—æ‰€ä½“ç°çš„â€”â€”è™½ç„¶"Tiny"ï¼Œä½†å¿—å‘è¿œå¤§ã€‚æˆ‘ä»¬ç›¸ä¿¡ï¼Œé€šè¿‡ç¤¾åŒºçš„å…±åŒåŠªåŠ›ï¼ŒTinyAIå¿…å°†åœ¨Java AIç”Ÿæ€ä¸­å‘æŒ¥é‡è¦ä½œç”¨ï¼Œä¸ºæ›´å¤šå¼€å‘è€…æ‰“å¼€AIä¸–ç•Œçš„å¤§é—¨ã€‚

**è®©æˆ‘ä»¬ä¸€èµ·ï¼Œç”¨Javaçš„æ–¹å¼ï¼Œæ‹¥æŠ±AIçš„æœªæ¥ï¼**

---

*å…³äºä½œè€…ï¼šå±±æ³½ï¼ŒAIæŠ€æœ¯çˆ±å¥½è€…ï¼ŒTinyAIé¡¹ç›®å‘èµ·äººã€‚è‡´åŠ›äºæ¨åŠ¨Javaåœ¨AIé¢†åŸŸçš„å‘å±•ï¼Œè®©æ›´å¤šJavaå¼€å‘è€…èƒ½å¤Ÿè½»æ¾è¸å…¥AIçš„ä¸–ç•Œã€‚*

*å¦‚æœæ‚¨å¯¹TinyAIé¡¹ç›®æ„Ÿå…´è¶£ï¼Œæ¬¢è¿è®¿é—®GitHubä»“åº“ï¼Œå‚ä¸å¼€æºè´¡çŒ®ï¼Œå…±åŒå»ºè®¾Java AIç”Ÿæ€ï¼*